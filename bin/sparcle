#!/bin/bash

LOG_DIR=/sparcle-logs
ARCHIVE_DIR=/sparcle-archive
DIST_DIR=/sparcle-dist
SHARED_DIR=/shared
BASE_SLAVE_PORT=61230
DATA_DIR_1=/data
DATA_DIR_1_5=
DATA_DIR_2=/Sparcle
APP_NAME=test-local
GPU_REGISTRY_PORT=60001
DEBUG=1

#OCSPARKDIR=${HOME}/src
#OCSPARKDIR=${HOME}/work/pointr/src
#OCSPARKNAME=OCspark
#OCSPARK=${OCSPARKDIR}/${DISTNAME}

HERE="$(cd "$(dirname "${BASH_SOURCE[0]}")" > /dev/null && pwd)"
OCSPARK="$(dirname "${HERE}")"
OCSPARKNAME="$(basename "${OCSPARK}")"
OCSPARKDIR="$(dirname "${OCSPARK}")"

## We assume we don't have to build here because it's the same arch as
## the build server.  However we do install (most of) the build tools
## since we might need them later.  Note: this follows bin/setupXgene.sh.

## Note: apt-get is idempotent so we don't have to check if a package
## is already installed before installing it.

## ----------------------------------------------------------------------------
## Infer the architecture and make sure it's recognized.
## ----------------------------------------------------------------------------

ARCH=$(uname -m)

if [ "${ARCH}" != "x86_64" ] && [ "${ARCH}" != "ARM" ]; then
    abort "Unexpected architecture inferred (expecting 'arch_64')"
fi


## ----------------------------------------------------------------------------
## Reportng.
## ----------------------------------------------------------------------------

function status { echo "$1." 1>&2; }
function abort { status "Aborting: $1"; exit 1; }

## ----------------------------------------------------------------------------
## Apply a function on another host (specified by IP).  Note: we
## hardcode USER in the ssh call because we might be using it in a
## declared function (eg. adopt-host) and don't want the function to
## use the remote value of USER (eg. nvidia).
## ----------------------------------------------------------------------------

function remote-op {
    callback=$1
    remote_host=$2
    user=$3

    [ "${remote_host}" == "" ] && abort "No remote host (ip addresses) supplied"

    if [ "${user}" != "" ]; then
        ssh ${user}@${remote_host}\
            -t "$(declare -f status abort ${callback}); USER=${USER}; ARCHIVE_DIR=${ARCHIVE_DIR}; LOG_DIR=${LOG_DIR}; DIST_DIR=${DIST_DIR}; SHARED_DIR=${SHARED_DIR}; DATA_DIR=${DATA_DIR}; VERSION=${VERSION}; ${callback}" ||
            abort "remote command failed"
    else
        ssh ${remote_host}\
            -t "$(declare -f status abort ${callback}); USER=${USER}; ARCHIVE_DIR=${ARCHIVE_DIR}; LOG_DIR=${LOG_DIR}; DIST_DIR=${DIST_DIR}; SHARED_DIR=${SHARED_DIR}; DATA_DIR=${DATA_DIR}; VERSION=${VERSION}; ${callback}" ||
            abort "remote command failed"
    fi
}

## ----------------------------------------------------------------------------
## Apply a function to all hosts in an IP file (can contain multiple
## slaves and/or one (at most) master).  Note: we use FD 3 in the
## while read (instead of stdin) to prevent ssh from slurping the
## whole of the input file on its first invocation.  (Alternatively we
## could use "ssh -n" in remote-op() but that would prevent us from
## using remote-op to send data to the remote hosts (eg. public keys,
## tarballs), so using a different FD in the read avoids the slurping
## problem and allows us to pass stdin through ssh when we want to.
## Note: we need to operate on the master last (after all the slave)
## if if we're starting services, but for now we'll just make sure the
## master appears at the end of the cluster definition file.
## ----------------------------------------------------------------------------

function cluster-op {
    master_callback=$1; shift
    slave_callback=$1; shift
    ip_file=$1; shift

    [ "${ip_file}" == "" ] && abort "No IP file supplied"
    [ -e ${ip_file} ] || abort "Supplied IP file '${ip_file}' not found"

    got_master="no"

    while read -u 3 -r line; do
        ip=$(echo $line | cut -f1 -d " ")
        class=$(echo $line | cut -f2 -d " ")

        echo "Processing ${class}: ${ip}" 1>&2

        if [ "${class}" == "slave" ]; then
            [ "${slave_callback}" != "" ] && ${slave_callback} ${ip} "$@"
        elif [ "${class}" == "master" ]; then
            [ "got_master" == "yes" ] &&\
                abort "Found more than one master in supplied IP file '${ip_file}'"

            got_master="yes"

            ## We sleep briefly before calling the master callback
            ## because if we're launching services then we appear to
            ## need to make sure that all the slaves are fully up
            ## before the master starts.

            if [[ "${VERSION}" == "1" ]]; then
                sleep 5
            elif [[ "${VERSION}" == "1.5" ]]; then
                sleep 1
            fi

            [ "${master_callback}" != "" ] && ${master_callback} ${ip} "$@"
        else
            abort "Found unexpected host class '${class}' in supplied IP file '${ip_file}' (expecting 'slave' or 'master')"
        fi
    done 3< <(cat ${ip_file} | egrep -v "^#")
}

function background-cluster-op {
    master_callback=$1; shift
    slave_callback=$1; shift
    ip_file=$1; shift

    [ "${ip_file}" == "" ] && abort "No IP file supplied"
    [ -e ${ip_file} ] || abort "Supplied IP file '${ip_file}' not found"

    got_master="no"

    while read -u 3 -r line; do
        ip=$(echo $line | cut -f1 -d " ")
        class=$(echo $line | cut -f2 -d " ")

        echo "Processing ${class}: ${ip}" 1>&2

        if [ "${class}" == "slave" ]; then
            [ "${slave_callback}" != "" ] && ${slave_callback} ${ip} "$@" &
        elif [ "${class}" == "master" ]; then
            [ "got_master" == "yes" ] &&\
                abort "Found more than one master in supplied IP file '${ip_file}'"

            got_master="yes"

            [ "${master_callback}" != "" ] && ${master_callback} ${ip} "$@" &
        else
            abort "Found unexpected host class '${class}' in supplied IP file '${ip_file}' (expecting 'slave' or 'master')"
        fi
    done 3< <(cat ${ip_file} | egrep -v "^#")

    trap 'exit' INT TERM
    trap 'kill 0' EXIT

    wait $(jobs -pr)
}

## ----------------------------------------------------------------------------
## Add a personal user on the specified host.  Uses the 'nvidia'
## (sudo) account to access the host in order to add the new account.
## ----------------------------------------------------------------------------

## Note: possible approaches to eliminating the need for the user
## interaction and multiple password entries:
##
##  See: https://serverfault.com/questions/841831/ssh-ask-password-once-reuse-password-until-timeout-finishes
##
##    sshpass
##    expect
##    ssh -o ControlPath...

## Need to make ${USER} evaluate to mike (ie. im the local shell
## *before* the function is declared and invoked by the remote shell).

function adopt {
    sudo adduser ${USER} || abort "adduser failed"
    sudo usermod -aG sudo ${USER} || abort "usermod failed"
}

function adopt-host { remote-op adopt $1 nvidia; }
function adopt-cluster { cluster-op adopt-host adopt-host $@; }

## ----------------------------------------------------------------------------
## Identify a host.
## ----------------------------------------------------------------------------

function identify {
    uname -a;
    df -h .
}

function identify-host { remote-op identify $1; }
function identify-cluster { cluster-op identify-host identify-host $@; }

## ----------------------------------------------------------------------------
## Add public ssh keys to new user on the specified host.
## ----------------------------------------------------------------------------

function authorize {
    mkdir -p ${HOME}/.ssh || abort "make ssh dir failed"
    cat >> ${HOME}/.ssh/authorized_keys || abort "append ssh keys failed"
}

function authorize-host {
    [ -e "${HOME}/.ssh/id_dsa.pub" ] || abort "No personal DSA public key found"
    [ -e "${HOME}/.ssh/id_rsa.pub" ] || abort "No personal RSA public key found"
    [ -e "${HOME}/.ssh/id_rsa.sparcle.pub" ] || abort "No sparcle RSA public key found"

    cat ${HOME}/.ssh/id_dsa.pub ${HOME}/.ssh/id_rsa.pub ${HOME}/id_rsa.sparcle.pub |
        remote-op authorize $1
}

function authorize-cluster { cluster-op authorize-host authorize-host $@; }

## ----------------------------------------------------------------------------
## Install packages for a worker (runtime only).  Note: GPUs must
## already have been set up with a Jetpack (including CUDNN, which
## seems not to be included by default).  Note: the oracle java
## installer is only available after an apt-get update.
## ----------------------------------------------------------------------------

function setup {
    sudo apt-add-repository universe || abort "set universe repo failed"
    sudo dpkg --configure -a || abort "dpkg configure failed"
    sudo apt-get update || abort "update failed"
    sudo apt-get install -y software-properties-common ||
        abort "install common properties failed"
    sudo apt-get install -y screen || abort "install screen failed"
    sudo apt-get install python-pip || abort "install pip failed"

    if [[ "${VERSION}" == "1" ]]; then
        ## Set up java.

        sudo add-apt-repository ppa:webupd8team/java || abort "set java repo failed"
        sudo apt-get install -y oracle-java8-installer || abort "install java failed"
        sudo apt-get install -y oracle-java8-set-default || abort "set default failed"
    else
        ## Install tensorflow (via wheel file we must distribute).

        pip install ${GIT_DIR}/wheel-files/tensorflow-1.5.0rc0-cp27-cp27mu-linux_aarch64.whl ||
            abort "install tensorflow failed"

        ## Set up for image handling.

        sudo apt install -y libjpeg-dev || abort "apt install libjpeg-dev failed"
        sudo apt install -y libblas-dev || abort "apt install libblas-dev failed"
        sudo apt install -y liblapack-dev || abort "apt install liblapack-dev failed"
        sudo pip install -y scikit-image || abort "pip install scikit-image failed"
        sudo pip install -y cython || abort "pip install cython"
        sudo pip install -y pyyaml || abort "pip install pyyaml failed"

        ## Install opencv.  See: https://jkjung-avt.github.io/opencv3-on-tx2/

        sudo apt-get purge libopencv*
        sudo apt-get purge python-numpy
        sudo apt autoremove
        sudo apt-get update
        sudo apt-get dist-upgrade
        sudo apt-get install -y --only-upgrade g++-5 cpp-5 gcc-5
        sudo apt-get install -y build-essential make cmake cmake-curses-gui\
             g++ libavformat-dev libavutil-dev libswscale-dev libv4l-dev libeigen3-dev\
             libglew-dev libgtk2.0-dev
        sudo apt-get install -y libdc1394-22-dev libxine2-dev libgstreamer1.0-dev\
             libgstreamer-plugins-base1.0-dev
        sudo apt-get install -y libjpeg8-dev libjpeg-turbo8-dev libtiff5-dev\
             libjasper-dev libpng12-dev libavcodec-dev
        sudo apt-get install -y libxvidcore-dev libx264-dev libgtk-3-dev\
             libatlas-base-dev gfortran
        sudo apt-get install -y libopenblas-dev liblapack-dev liblapacke-dev
        sudo apt-get install -y qt5-default
        sudo apt-get install -y python3-dev python3-pip python3-tk
        sudo pip3 install numpy
        sudo pip3 install matplotlib
        ##sudo vim /usr/local/lib/python3.5/dist-packages/matplotlib/mpl-data/matplotlibrc
        sudo apt-get install -y python-dev python-pip python-tk
        sudo pip2 install numpy
        sudo pip2 install matplotlib
        ##sudo vim /usr/local/lib/python2.7/dist-packages/matplotlib/mpl-data/matplotlibrc
        ##sudo vim /usr/local/cuda/include/cuda_gl_interop.h
        (cd /usr/lib/aarch64-linux-gnu/ &&\
             sudo ln -sf tegra/libGL.so libGL.so)
        mkdir -p ${HOME}/src
        (cd ${HOME}/src
             wget https://github.com/opencv/opencv/archive/3.4.0.zip\
                  -O opencv-3.4.0.zip
             unzip opencv-3.4.0.zip
             cd opencv-3.4.0
             mkdir -p build
             cd build
             cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local\
                   -D WITH_CUDA=ON -D CUDA_ARCH_BIN="6.2" -D CUDA_ARCH_PTX=""\
                   -D WITH_CUBLAS=ON -D ENABLE_FAST_MATH=ON -D CUDA_FAST_MATH=ON\
                   -D ENABLE_NEON=ON -D WITH_LIBV4L=ON -D BUILD_TESTS=OFF\
                   -D BUILD_PERF_TESTS=OFF -D BUILD_EXAMPLES=OFF\
                   -D WITH_QT=ON -D WITH_OPENGL=ON ..
             make -j4
             sudo make install)
    fi

    ## Create a password-free sudoable wrapper around odi.py.

##     sudo cat > /etc/sudoers.d/odi <<EOF
## %admin ALL=(ALL:ALL) NOPASSWD: /usr/local/sbin/odi.sh
##  
## EOF
##     sudo cat > /usr/local/sbin/odi.sh <<EOF
## #!/bin/bash
## 
## cd /home/mike/realtime_object_detection && ./odi.py
## 
## EOF
## 
##     sudo chmod root:root /usr/local/sbin/odi.sh
##     sudo chown go-rwx /usr/local/sbin/odi.sh

    ## Better: just add your own user to the video group (edit
    ## /etc/group and append your username to the line that defines
    ## the group 'video').
}

function setup-host { remote-op setup $1; }
function setup-cluster { cluster-op setup-host setup-host $@; }

## ----------------------------------------------------------------------------
## Install packages for a build server.
## ----------------------------------------------------------------------------

function setup-for-building {
    ## Set up java.

    sudo add-apt-repository ppa:webupd8team/java || abort "set java repo failed"
    sudo apt-get update || abort "update failed"
    sudo apt-get install -y oracle-java8-installer || abort "install java failed"
    sudo apt-get install -y oracle-java8-set-default || abort "set default failed"

    ## Set up scala.

    sudo wget www.scala-lang.org/files/archive/scala-2.11.8.deb ||
        abort "fetch scala failed"
    sudo dpkg -i scala-2.11.8.deb || abort "install scala failed"

    ## Set up misc other packages.

    sudo apt-get install -y screen || abort "install screen failed"
    sudo apt get install -y software-properties-common ||
        abort "install common properties failed"

    ## Set up maven.

    sudo apt-add-repository universe || abort "add universe repo failed"
    sudo apt-get update || abort "update failed"
    sudo apt-get install -y maven || abort "install maven failed"

    ## Set up yq.  Note: not needed any more.

##    sudo add-apt-repository ppa:rmescandon/yq || abort "add yq repo failed"
##    sudo apt update || abort "update failed"
##    sudo apt install -y yq || abort "install yq failed"
}

function setup-host-for-building { remote-op setup-for-building $1; }

## ----------------------------------------------------------------------------
## Create a clone of the sparcle repo.
## ----------------------------------------------------------------------------

function clone {
    (cd ${HOME} && mkdir -p ${OCSPARKDIR}) || abort "mkdir failed"
    (cd ${OCSPARKDIR} && git clone https://github.com/OpenChaiSpark/OCspark.git) ||
        abort "git clone failed"
    (cd ${OCSPARK} && git checkout -b v3 origin/v3) || abort "git branch failed"
    (cd ${OCSPARK} && git pull) || abort "git pull failed"
}

function remote-clone { remote-op clone $1; }

## ----------------------------------------------------------------------------
## Build.
## ----------------------------------------------------------------------------

## Note: there is apparently a circular dependency: you have to do
## some combination of "./bin/buildtf.arm.sh", "(cd tfdma;
## ./build.arm.sh)" and "mvn package", in some order, in order to get
## "./bin/buildtf.arm.sh" building properly.
##
## Need to add some include paths for gcc:
##
##   For jni.h:     /usr/lib/jvm/java-8-oracle/include
##   For jni_md.h:  /usr/lib/jvm/java-8-oracle/include/linux
##   Other headers: /usr/include
##   Other headers: /usr/include/linux
##   Other headers: /usr/local/include

function build {
    export CPATH=/usr/lib/jvm/java-8-oracle/include:/usr/lib/jvm/java-8-oracle/include/linux:/usr/include:/usr/include/linux:/usr/local/include
    export GITDIR=${OCSPARK}
    (cd ${GITDIR} && mvn install && ./bin/buildtf.arm.sh) ||
        abort "git maven build failed"
    (cd ${GITDIR}/newapp && make) || abort "git make newapp failed"
}

function remote-build { remote-op build $1; }

## ----------------------------------------------------------------------------
## Create a sparcle package (tarball) ready to deploy to remote hosts.
## ----------------------------------------------------------------------------

function package {
    (cd ${OCSPARKDIR} && tar czvf ${HOME}/ocspark-${ARCH}.tgz ${OCSPARKNAME}) ||
        abort "create package failed"
}

function remote-package { remote-op package $1; }

## ----------------------------------------------------------------------------
## Deploy an OCspark directory.
## ----------------------------------------------------------------------------

function deploy-app {
    app_dir=$1

    [ -d ${app_dir} ] || abort "can't find app dir"

    parent_dir=$(dirname ${app_dir})
    target_dir=$(basename ${app_dir})

    [ -d ${HOME}/${target_dir} ] && abort "app dir already deployed"

    (cd $parent_dir && tar -cz ${target_dir}) | (cd && tar -xz) ||
        abort "deployment of app dir failed"
}

function deploy-app-to-host {
    ip=$1
    app_dir=$2

    [ -d ${app_dir} ] || abort "can't find app dir"

    parent_dir=$(dirname ${app_dir})
    target_dir=$(basename ${app_dir})

    ssh ${ip} "ls -d ${target_dir} > /dev/null 2>&1" &&
        abort "Remote sparcle already present"

    (cd ${parent_dir} && tar -cz ${target_dir}) | ssh ${ip} "tar -xz" ||
        abort "deployment of app dir failed"
}

function deploy-app-to-cluster {
    ip_file=$1
    app_dir=$2

    cluster-op deploy-app-to-host deploy-app-to-host "${ip_file}" "${app_dir}"
}

## ----------------------------------------------------------------------------
## Start a slave (typically on a GPU).  Note: slaves must be started
## before the master.  Note: we must call "set -m" to prevent the
## discconnection of the tty (created by "ssh -t") from killing the
## slave process (even thought it's nohup'd).  Note: we wrap the IP
## extraction in an echo to trim whitespace.  Note: sync dir is for
## sparcle2.
## ----------------------------------------------------------------------------

function start-slave {
    local ip=$(echo $(hostname -I | cut -f1 -d" " 2> /dev/null))

    [[ "${ip}" == "" ]] && abort "failed to look up IP address"

    local port=$(fgrep ${ip} ${SHARED_DIR}/gpu-slaves.txt | cut -f2 -d" " | cut -f2 -d:)

    [[ "${port}" == "" ]] && abort "failed to look up port from ip ${ip}"

    local slave_number=$(echo $(grep -n ${ip} ${SHARED_DIR}/gpu-slaves.txt | cut -f1 -d:))

    [[ "${slave_number}" == "" ]] && abort "failed to look up slave number from ip ${ip}"

    ## Create the log dir if necessary.

    if [ ! -d "${LOG_DIR}" ]; then
        sudo mkdir -p "${LOG_DIR}" || abort "creating log dir failed"
        sudo chmod a+rwx "${LOG_DIR}" || abort "setting log dir permissions failed"
    fi

    ## Create the data dir if necessary.

    if [[ "${DATA_DIR}" != "" && ! -d "${DATA_DIR}" ]]; then
        sudo mkdir ${DATA_DIR} || abort "creating data dir failed"
        sudo chmod -R a+rwxs "${DATA_DIR}" || abort "setting data dir permissions failed"
    fi

    ## Make sure there are no existing slave processes running.

    local log_ext="$(mktemp -u XXXXXX)"

    if [[ "${VERSION}" == "1" ]]; then
        mkdir -p "${DATA_DIR}/input" || abort "creating input dir failed"
        mkdir -p "${DATA_DIR}/output" || abort "creating output dir failed"
        mkdir -p "${DATA_DIR}/tmp" || abort "creating tmp dir failed"

        if (pgrep -f "^java .+ -jar ${SHARED_DIR}/tf" > /dev/null); then
            status "slave already running"
        else
            ## Archive the old log file if present.

            local log_file="${LOG_DIR}/slave"

            if [[ -e "${log_file}" ]]; then
                mv "${log_file}" "${log_file}.${log_ext}" ||
                    abort "archiving old slave log file ${log_file} failed"
            fi

            ## Start the slave process.

            set -m

            nohup ${SHARED_DIR}/runtfserver.sh localhost ${port} > ${log_file} 2>&1 ||
                abort "starting slave on ip ${ip} port ${port} failed" &
            status "started slave on ip ${ip} port ${port}"
        fi

        if (pgrep -f "^/usr/bin/perl /shared/dummytf.pl ${DATA_DIR}" > /dev/null); then
            status "dummytf already running"
        else
            ## Archive the old log file if present.

            local dummy_log_file="${LOG_DIR}/dummytf"

            if [[ -e "${dummy_log_file}" ]]; then
                mv "${dummy_log_file}" "${dummy_log_file}.${log_ext}" ||
                    abort "archiving old dummytf log file ${dummy_log_file} failed"
            fi

            ## Start the dummy tensorflow process.

            set -m

            nohup ${SHARED_DIR}/dummytf.pl "${DATA_DIR}/tmp" > ${dummy_log_file} 2>&1 ||
                abort "starting dummytf on ip ${ip} failed" &
            status "started dummytf on ip ${ip}"
        fi
    elif [[ "${VERSION}" == "1.5" ]]; then
        mkdir -p "${DATA_DIR}/ingress" || abort "creating sync input dir failed"
        mkdir -p "${DATA_DIR}/egress" || abort "creating sync output dir failed"

        if (pgrep -f "^python2 ./odi.py" > /dev/null); then
            status "odi.py already running"
        else
            ## Archive the old log file if present.

            local tf_log_file="${LOG_DIR}/odi"

            if [[ -e "${tf_log_file}" ]]; then
                mv "${tf_log_file}" "${tf_log_file}.${log_ext}" ||
                    abort "archiving old odi.py log file ${tf_log_file} failed"
            fi

            ## Start the tensorflow processes.

            set -m

            cd ${SHARED_DIR}/realtime_object_detection
            nohup ./odi.py > ${tf_log_file} 2>&1 ||
                abort "starting odi.py on ip ${ip} failed" &
            status "started odi.py on ip ${ip}"

            sleep 180   ## should really find a way to wait until service is fully up.
        fi

        if (pgrep -f "^python sparcle-client.py" > /dev/null); then
            status "sparcle 1.5 slave already running"
        else
            ## Archive the old log file if present.

            local log_file="${LOG_DIR}/sparcle-1.5.log"

            if [[ -e "${log_file}" ]]; then
                mv "${log_file}" "${log_file}.${log_ext}" ||
                    abort "archiving old sparcle 1.5 slave log file ${log_file} failed"
            fi

            ## Start the sparcle 1.5 client.

            local offset_slave_number=$((${slave_number} - 1))
            set -m

            rm ${DATA_DIR}/egress/sparcle-client.py 2> /dev/null || true
            cp ${SHARED_DIR}/sparcle-client.py ${DATA_DIR}/egress/ ||
                abort "copying sparcle 1.5 client to egress dir failed"
            cd ${DATA_DIR}/egress
            python sparcle-client.py ${offset_slave_number} > ${log_file} 2>&1 ||
                abort "starting sparcle 1.5 slave ${slave_number} on ip ${ip} failed" &
            status "started sparcle 1.5 slave ${slave_number} on ip ${ip}"
        fi
    else
        mkdir -p "${DATA_DIR}/sync/in" || abort "creating sync input dir failed"
        mkdir -p "${DATA_DIR}/sync/out" || abort "creating sync output dir failed"

        if (pgrep -f "^lsyncd" > /dev/null); then
            status "slave sync already running"
        else
            ## Archive the old log file if present.

            local log_file="${LOG_DIR}/sync.log"

            if [[ -e "${log_file}" ]]; then
                mv "${log_file}" "${log_file}.${log_ext}" ||
                    abort "archiving old slave sync log file ${log_file} failed"
            fi

            ## Start the sync process.

            set -m

            lsyncd -log all ${SHARED_DIR}/sync/slave-${slave_number}.lua ||
                abort "starting slave sync ${slave_number} on ip ${ip} failed"
            status "started slave sync ${slave_number} on ip ${ip}"
        fi

        if (pgrep -f "^/usr/bin/perl /shared/dummytf.pl ${DATA_DIR}" > /dev/null); then
            status "dummytf already running"
        else
            ## Archive the old log file if present.

            local dummy_log_file="${LOG_DIR}/dummytf"

            if [[ -e "${dummy_log_file}" ]]; then
                mv "${dummy_log_file}" "${dummy_log_file}.${log_ext}" ||
                    abort "archiving old dummytf log file ${dummy_log_file} failed"
            fi

            ## Start the dummy tensorflow processes.

            set -m

            nohup ${SHARED_DIR}/dummytf.pl "${DATA_DIR}/sync" > ${dummy_log_file} 2>&1 ||
                abort "starting dummytf on ip ${ip} failed" &
            status "started dummytf on ip ${ip}"
        fi
    fi
}

function start-remote-slave { remote-op start-slave $1; }
function start-cluster-slaves { cluster-op "" start-remote-slave $@; }

## ----------------------------------------------------------------------------
## Stop a slave on a remote host (typically a GPU).  Note: we match
## java as the start of the string in order to avoid matching the
## pkill command itself.  Note: we make this idempotent by ignoring an
## error condition.
## ----------------------------------------------------------------------------

function stop-slave {
    local slave_pattern
    local tensorflow_pattern

    if [[ "${VERSION}" == "1" ]]; then
        slave_pattern="^java .+ -jar ${SHARED_DIR}/tf"
        tensorflow_pattern="^/usr/bin/perl /shared/dummytf.pl ${DATA_DIR}"
    elif [[ "${VERSION}" == "1.5" ]]; then
        slave_pattern="^python sparcle-client.py"
        tensorflow_pattern="^python2 ./odi.py"
    else
        slave_pattern="^lsyncd"
        tensorflow_pattern="^/usr/bin/perl /shared/dummytf.pl ${DATA_DIR}"
    fi

    if (pgrep -f "${slave_pattern}" > /dev/null); then
        pkill -f "${slave_pattern}" || abort "stopping slave failed"
        status "stopped slave"
    else
        status "slave already stopped"
    fi

    if (pgrep -f "${tensorflow_pattern}" > /dev/null); then
        pkill -f "${tensorflow_pattern}" || abort "stopping tensorflow failed"
        status "stopped tensorflow"
    else
        status "tensorflow already stopped"
    fi
}

function stop-remote-slave { remote-op stop-slave $1; }
function stop-cluster-slaves { cluster-op "" stop-remote-slave $@; }

## ----------------------------------------------------------------------------
## Stop a slave on a remote host (typically a GPU).  Note: we match
## java as the start of the string in order to avoid matching the
## pkill command itself.  Note: we make this idempotent by ignoring an
## error condition.
## ----------------------------------------------------------------------------

function stop-tensorflow {
    local tensorflow_pattern

    if [[ "${VERSION}" == "1" ]]; then
        tensorflow_pattern="^/usr/bin/perl /shared/dummytf.pl ${DATA_DIR}"
    elif [[ "${VERSION}" == "1.5" ]]; then
        tensorflow_pattern="^python2 ./odi.py"
    else
        tensorflow_pattern="^/usr/bin/perl /shared/dummytf.pl ${DATA_DIR}"
    fi

    if (pgrep -f "${tensorflow_pattern}" > /dev/null); then
        pkill -f "${tensorflow_pattern}" || abort "stopping tensorflow failed"
        status "stopped tensorflow"
    else
        status "tensorflow already stopped"
    fi
}

function stop-remote-tensorflow { remote-op stop-tensorflow $1; }
function stop-cluster-tensorflows { cluster-op "" stop-remote-tensorflow $@; }

## ----------------------------------------------------------------------------
## Start a master (eg. on x-gene or i3).
## ----------------------------------------------------------------------------

function start-master {
    ## Make sure the IP address matches the config.

    local ip=$(echo $(hostname -I | cut -f1 -d" " 2> /dev/null))
    local registry_ip=$(echo $(fgrep gpuRegistryHost ${SHARED_DIR}/conf/apps-config.yml | cut -f2 -d:))

    if [[ "${ip}" != "" ]] && [[ "${registry_ip}" != "" ]] &&
           [[ "${ip}" != "${registry_ip}" ]]; then
        abort "host ip <${ip}> does not match gpu registry ip <${registry_ip}>"
    fi

    local slave_count=$(echo $(wc -l ${SHARED_DIR}/gpu-slaves.txt | cut -f1 -d" "))

    ## Create the log dir if necessary.

    if [[ ! -d "${LOG_DIR}" ]]; then
        sudo mkdir -p "${LOG_DIR}" || abort "creating log dir failed"
        sudo chmod a+rwx "${LOG_DIR}" || abort "setting log dir permissions failed"
    fi

    ## Create the data dir if necessary.

    if [[ "${DATA_DIR}" != "" && ! -d "${DATA_DIR}" ]]; then
        sudo mkdir ${DATA_DIR} || abort "creating data dir failed"
        sudo chmod -R a+rwx "${DATA_DIR}" || abort "setting data dir permissions failed"
    fi

    ## Start services.

    local log_ext="$(mktemp -u XXXXXX)"

    if [[ "${VERSION}" == "1" ]]; then
        mkdir -p "${DATA_DIR}/input" || abort "creating input dir failed"
        mkdir -p "${DATA_DIR}/output" || abort "creating output dir failed"
        mkdir -p "${DATA_DIR}/tmp" || abort "creating tmp dir failed"

        if (pgrep -f "^java .+ org.openchai.tensorflow.DirectSubmitter" > /dev/null); then
            status "master already running"
        else
            ## Archive the old log file if present.

            local log_ext="$(mktemp -u XXXXXX)"
            local log_file="${LOG_DIR}/master"

            if [[ -e "${log_file}" ]]; then
                mv "${log_file}" "${log_file}.${log_ext}" ||
                    abort "archiving old master log file ${log_file} failed"
            fi

            ## Start the master.  Note: can also try -Xmx4096m

            set -m

            export GITDIR=${DIST_DIR}
            nohup java -Xmx2048m -Dlogger.level=2 -classpath ${DIST_DIR}/tf/target/classes:${DIST_DIR}/tf/libs/* -Djava.net.preferIPv4Stack=true org.openchai.tensorflow.DirectSubmitter ${SHARED_DIR}/conf/submitter.yml > ${log_file} 2>&1 ||
                abort "starting master on ip ${ip} failed" &
            status "started master on ip ${ip}"
        fi
    elif [[ "${VERSION}" == "1.5" ]]; then
        for i in $(seq 1 ${slave_count}); do
            mkdir -p "${DATA_DIR}/ingress/${i}" ||
                abort "creating sparcle 1.5 master input subdir ${i} failed"
            mkdir -p "${DATA_DIR}/egress/${i}" ||
                abort "creating sparcle 1.5 master output subdir ${i} failed"
        done

        if (pgrep -f "^python sparcle-server.py" > /dev/null); then
            status "sparcle 1.5 master already running"
        else
            ## Archive the old log file if present.

            local log_file="${LOG_DIR}/sparcle-1.5-master.log"

            if [[ -e "${log_file}" ]]; then
                mv "${log_file}" "${log_file}.${log_ext}" ||
                    abort "archiving old sparcle 1.5 master log file ${log_file} failed"
            fi

            ## Start the sync process.

            local slave_count=$(echo $(wc -l ${SHARED_DIR}/gpu-slaves.txt | cut -f1 -d" "))
            local offset_slave_count=$((${slave_count} - 1))
            
            for j in $(seq 0 ${offset_slave_count}); do
                cp ${SHARED_DIR}/realtime_object_detection/test_images/images/*.jpg\
                   ${DATA_DIR}/egress/${j}/
            done

            set -m

            cd ${SHARED_DIR}
            python sparcle-server.py --server > ${log_file} 2>&1 ||
                abort "starting sparcle 1.5 master on ip ${ip} failed" &
            status "started sparcle 1.5 master on ip ${ip}"
        fi
    else
        for i in $(seq 1 ${slave_count}); do
            mkdir -p "${DATA_DIR}/sync/in/${i}" ||
                abort "creating sync input subdir ${i} failed"
            mkdir -p "${DATA_DIR}/sync/out/${i}" ||
                abort "creating sync output subdir ${i} failed"
        done

        if (pgrep -f "^lsyncd" > /dev/null); then
            status "master sync already running"
        else
            ## Archive the old log file if present.

            local log_file="${LOG_DIR}/sync.log"

            if [[ -e "${log_file}" ]]; then
                mv "${log_file}" "${log_file}.${log_ext}" ||
                    abort "archiving old master sync log file ${log_file} failed"
            fi

            ## Start the sync process.

            set -m

            lsyncd -log all ${SHARED_DIR}/sync/master.lua ||
                abort "starting master sync on ip ${ip} failed"
            status "started master sync on ip ${ip}"
        fi
    fi
}

function start-remote-master { remote-op start-master $1; }
function start-cluster-masters { cluster-op start-remote-master "" $@; }

## ----------------------------------------------------------------------------
## Stop a master on a remote host.
## ----------------------------------------------------------------------------

function stop-master {
    local pattern

    if [[ "${VERSION}" == "1" ]]; then
        pattern="^java .+ org.openchai.tensorflow.DirectSubmitter"
    elif [[ "${VERSION}" == "1.5" ]]; then
        pattern="^python sparcle-server.py --server"
    else
        pattern="^lsyncd"
    fi

    if (pgrep -f "${pattern}" > /dev/null); then
        pkill -f "${pattern}" || abort "stopping master failed"
        status "stopped master"
    else
        status "master already stopped"
    fi
}

function stop-remote-master { remote-op stop-master $1; }
function stop-cluster-masters { cluster-op stop-remote-master "" $@; }

## ----------------------------------------------------------------------------
## Wrap the remote cluster operation.
## ----------------------------------------------------------------------------

function start-cluster { cluster-op start-remote-master start-remote-slave $@; }
function stop-cluster { cluster-op stop-remote-master stop-remote-slave $@; }

## ----------------------------------------------------------------------------
## Start a simulate process on the master.
## ----------------------------------------------------------------------------

function start-simulator {
    ## Make sure there are no existing simulator processes running.

    local pattern="^/usr/bin/perl simulate.pl"

    if (pgrep -f "${pattern}" > /dev/null); then
        status "simulator already running"
        return
    fi

    ## Create the log dir if necessary.

    if [[ ! -d "${LOG_DIR}" ]]; then
        sudo mkdir -p "${LOG_DIR}" || abort "creating log dir failed"
        sudo chmod a+rwx "${LOG_DIR}" || abort "setting log dir permissions failed"
    fi

    ## Create the data dir if necessary.

    if [[ "${DATA_DIR}" != "" && ! -d "${DATA_DIR}" ]]; then
        sudo mkdir ${DATA_DIR} || abort "creating data dir failed"
        sudo chmod -R a+rwx "${DATA_DIR}" || abort "setting data dir permissions failed"
    fi

    ## Make sure the IP address matches the config.

    local ip=$(echo $(hostname -I | cut -f1 -d" " 2> /dev/null))
    local registry_ip=$(echo $(fgrep gpuRegistryHost ${SHARED_DIR}/conf/apps-config.yml | cut -f2 -d:))

    if [[ "${ip}" != "" ]] && [[ "${registry_ip}" != "" ]] &&
           [[ "${ip}" != "${registry_ip}" ]]; then
        abort "host ip <${ip}> does not match gpu registry ip <${registry_ip}>"
    fi

    ## Start the simulator.

    set -m

    if [[ "${VERSION}" == "1" ]]; then
        mkdir -p "${DATA_DIR}/input" || abort "creating input dir failed"
        mkdir -p "${DATA_DIR}/output" || abort "creating output dir failed"
        mkdir -p "${DATA_DIR}/tmp" || abort "creating tmp dir failed"

        ## Archive the old log file if present.

        local log_ext="$(mktemp -u XXXXXX)"
        local log_file="${LOG_DIR}/simulate"

        if [[ -e "${log_file}" ]]; then
            mv "${log_file}" "${log_file}.${log_ext}" ||
                abort "archiving old simulator log file ${log_file} failed"
        fi

        ## Start the simulator.

        nohup ${SHARED_DIR}/simulate.pl "${DATA_DIR}" > ${log_file} 2>&1 ||
            abort "starting simulator on ip ${ip} failed" &
        status "started simulator on ip ${ip}"
    elif [[ "${VERSION}" == "1.5" ]]; then
        local slave_count=$(echo $(wc -l ${SHARED_DIR}/gpu-slaves.txt | cut -f1 -d" "))
        local offset_slave_count=$((${slave_count} - 1))

        for i in $(seq 0 ${max_slave}); do
            mkdir -p "${DATA_DIR}/ingress/${i}" ||
                abort "creating sync input subdir ${i} failed"
            mkdir -p "${DATA_DIR}/egress/${i}" ||
                abort "creating sync output subdir ${i} failed"
        done

        declare -i i

        local i=0
#        local period_s=1
        local period_s=0.027

        while sleep $period_s; do
            i=$((i + 1))
            for j in $(seq 0 ${offset_slave_count}); do
                cp ${SHARED_DIR}/test.jpg ${DATA_DIR}/egress/${j}/test-${i}.jpg
            done &
        done
    else
        local slave_count=$(echo $(wc -l ${SHARED_DIR}/gpu-slaves.txt | cut -f1 -d" "))

        for i in $(seq 1 ${slave_count}); do
            mkdir -p "${DATA_DIR}/sync/in/${i}" ||
                abort "creating sync input subdir ${i} failed"
            mkdir -p "${DATA_DIR}/sync/out/${i}" ||
                abort "creating sync output subdir ${i} failed"
        done

        declare -i i

        local i=0
#        local period_s=1
        local period_s=0.027

        while sleep $period_s; do
            i=$((i + 1))
            for j in $(seq 1 ${slave_count}); do
                cp ${SHARED_DIR}/test.jpg ${DATA_DIR}/sync/out/${j}/test-${i}.jpg
            done &
        done
    fi
}

function start-remote-simulator { remote-op start-simulator $1; }
function start-cluster-simulators { cluster-op start-remote-simulator "" $@; }

## ----------------------------------------------------------------------------
## Stop a simulate process on a remote host.
## ----------------------------------------------------------------------------

function stop-simulator {
    local pattern="^/usr/bin/perl /shared/simulate.pl"

    if (pgrep -f "${pattern}" > /dev/null); then
        pkill -f "${pattern}" || abort "killing simulator failed"
        status "killed simulator"
    else
        status "simulator already stopped"
    fi
}

function stop-remote-simulator { remote-op stop-simulator $1; }
function stop-cluster-simulators { cluster-op stop-remote-simulator "" $@; }

## ----------------------------------------------------------------------------
## Tail slave log files.  Try "tail -fv" first to force a hedaer even
## for a single file, then faillback to "tail -f" if necessary.
## ----------------------------------------------------------------------------

#(ssh cpu tail -vf /sparcle-logs/master & ssh gpu-4 tail -vf /sparcleogs/slave /sparcle-logs/dummytf)

function monitor-slave {
    tail -fv "${LOG_DIR}/slave" "${LOG_DIR}/dummytf" 2> /dev/null ||
        tail -f "${LOG_DIR}/slave" "${LOG_DIR}/dummytf" 2> /dev/null
}

function monitor-remote-slave { remote-op monitor-slave $1; }
function monitor-cluster-slaves { background-cluster-op "" monitor-remote-slave $@; }

## ----------------------------------------------------------------------------
## Tail master log files.  Try "tail -fv" first to force a hedaer even
## for a single file, then faillback to "tail -f" if necessary.
## ----------------------------------------------------------------------------

function monitor-master {
    tail -fv "${LOG_DIR}/master" "${LOG_DIR}/simulator" 2> /dev/null ||
        tail -f "${LOG_DIR}/master" "${LOG_DIR}/simulator" 2> /dev/null
}

function monitor-remote-master { remote-op monitor-master $1; }
function monitor-cluster-masters { background-cluster-op monitor-remote-master "" $@; }

## ----------------------------------------------------------------------------
## Tail all log files.
## ----------------------------------------------------------------------------

function monitor-cluster {
    background-cluster-op monitor-remote-master monitor-remote-slave $@
}

## ----------------------------------------------------------------------------
## Create a gpu-slaves.txt file.  Note: we increment a local
## slave_number variable to assign ports.
## ----------------------------------------------------------------------------

declare -i slave_count
declare -i slave_port_offset

function make-gpu-slaves-entry {
    ip=$1

    port=$((${BASE_SLAVE_PORT} + ${slave_port_offset}))
    slave_port_offset=$((${slave_port_offset} + 10))
    slave_count=$((${slave_count} + 1))

    echo "${slave_count} ${ip}:${port} ${APP_NAME} ${DATA_DIR}/input ${DATA_DIR}/output"
}

function make-gpu-slaves {
    ip_file=$1
    output_file=$2

    [ -e ${output_file} ] && abort "gpu-slaves file already exists"

    echo "Making gpu-slaves file" 1>&2

    slave_count=0
    slave_port_offset=0

    cluster-op "" make-gpu-slaves-entry "${ip_file}" > ${output_file}
}

## ----------------------------------------------------------------------------
## Create a submitter.yml file.  Based on
## tf/target/classes/submitter.yml.
## ----------------------------------------------------------------------------

## TODO: could replace the cat with calls to yq.
## TODO: make sure we actually need this (it's passed to java as an argument
## to start the master, but the tests on the lab machines didn't have it and
## worked anyway.

function make-submitter-master {
    ip=$1

    cat << EOF
map:
  main :
    appType: direct
    imageExtensions:
      - jpg
      - jpeg
      - png
      - gif
      - svg
      - tiff
      - mpg
    batchSize: 2
    gpuRegistryHost: ${ip}
    gpuRegistryPort: "${GPU_REGISTRY_PORT}"
EOF
}

function make-submitter {
    ip_file=$1
    output_file=$2

    [ -e ${output_file} ] && abort "submitter file already exists"

    echo "Making submitter file" 1>&2

    cluster-op make-submitter-master "" "${ip_file}" > ${output_file}
}

## ----------------------------------------------------------------------------
## Create an apps-config.yml file.
## ----------------------------------------------------------------------------

## TODO: could replace the cat with calls to yq.

function make-apps-config-master {
    ip=$1

    cat << EOF
connections:
  gpuRegistryHost: ${ip}
  gpuRegistryPort: "${GPU_REGISTRY_PORT}"
defaults:
  apps:
    ${APP_NAME}:
      cmdline: '${SHARED_DIR}/newapp \${1} '
      rundir: \${POINTR_HOME}
      tmpdir: ${DATA_DIR}/tmp
environments:
  linux:
    env:
      POINTR_HOME: ${SHARED_DIR}/pointr
      TENSORFLOW_HOME: /home/ubuntu/tensorflow
      DARKNET_HOME: /git/darknet
      TF_CPP_MIN_LOG_LEVEL: "2"
  osx:
    env:
      POINTR_HOME: /tmp
      TENSORFLOW_HOME: /tmp
      DARKNET_HOME: /tmp
      TF_CPP_MIN_LOG_LEVEL: "2"
EOF
}

function make-apps-config {
    ip_file=$1
    output_file=$2

    [ -e ${output_file} ] && abort "apps-config file already exists"

    echo "Making apps-config file" 1>&2

    cluster-op make-apps-config-master "" "${ip_file}" > ${output_file}
}

## ----------------------------------------------------------------------------
## Create a master sync config file.
## ----------------------------------------------------------------------------

declare -i slave_count

function add-master-sync-config-slave {
    ip=$1

    slave_count=$((${slave_count} + 1))

    echo "   { \"${ip}\", \"${DATA_DIR}/sync/out/${slave_count}\" },"
}

function make-master-sync-config {
    ip_file=$1
    output_file=$2

    [ -e ${output_file} ] && abort "sync config file already exists"

    echo "Making master sync config file" 1>&2

    slave_count=0

    echo "gpus = {" > ${output_file}
    cluster-op "" add-master-sync-config-slave "${ip_file}" >> ${output_file}
    echo "}" >> ${output_file}

    cat <<EOF >> ${output_file}

settings {
   logfile = "${LOG_DIR}/sync.log",
   statusFile = "${LOG_DIR}/sync.status",
   maxDelays = 0
}

for _, v in ipairs(gpus) do
   server = v[1]
   origin = v[2]
   print(server, origin)
   sync {
      default.rsync,
      delete = 'running',
      source = origin,
      target = server .. ':' .. "${DATA_DIR}/ingress/",
      delay = 0,
      rsync = {
         rsh = "/usr/bin/ssh -l mike -i /home/mike/.ssh/id_rsa.sparcle",
--         temp_dir = "/tmp",
--         update = true,
--         _extra = { "--remove-source-files" }
      }
   }
end

EOF
}

## ----------------------------------------------------------------------------
## Create multiple slave sync config files.
## ----------------------------------------------------------------------------

declare master_ip

function get-master-ip { master_ip="$1"; }

declare -i slave_count
declare slave_sync_config_dir

function make-slave-sync-config {
    local ip=$1

    slave_count=$((${slave_count} + 1))

    local output_file="${slave_sync_config_dir}/slave-${slave_count}.lua"

    [ -e ${output_file} ] &&
        abort "slave sync config file ${slave_count} already exists"

    local sync_path="${DATA_DIR}/sync/in/${slave_count}"

    echo "Making slave sync config file ${slave_count}" 1>&2

    cat <<EOF >> ${output_file}

settings {
   logfile = "${LOG_DIR}/sync.log",
   statusFile = "${LOG_DIR}/sync.status",
   maxDelays = 0
}

 sync {
    default.rsync,
    delete = "running",
    source = "${DATA_DIR}/egress",
    target = "${master_ip}:${DATA_DIR}/sync/in/${slave_count}/",
    delay = 0,
    rsync = {
       rsh = "/usr/bin/ssh -l mike -i /home/mike/.ssh/id_rsa.sparcle",
       rsync_path = "mkdir -p ${sync_path} && /usr/bin/rsync",
--       temp_dir = "/tmp",
--       update = true,
--       _extra = { "--remove-source-files" }
    }
 }

EOF
}

function make-slave-sync-configs {
    local ip_file=$1

    cluster-op get-master-ip "" "${ip_file}"

    slave_count=0
    slave_sync_config_dir=$2

    cluster-op "" make-slave-sync-config "${ip_file}"
}

## ----------------------------------------------------------------------------
## Create a shared directory (tarball) ready for deployment.  Note:
## sync dir and master and slave sync config files are for sparcle2.
## ----------------------------------------------------------------------------

function make-shared {
    ip_file=$1
    shared_dir=$2

    [ "${shared_dir}" == "" ] && abort "shared dir not specified"

    mkdir -p ${shared_dir}/conf || abort "can't make shared conf subdirectory"
    mkdir -p ${shared_dir}/sync || abort "can't make shared sync subdirectory"

    make-gpu-slaves ${ip_file} ${shared_dir}/gpu-slaves.txt
    make-apps-config ${ip_file} ${shared_dir}/conf/apps-config.yml
    make-submitter ${ip_file} ${shared_dir}/conf/submitter.yml
    make-master-sync-config ${ip_file} ${shared_dir}/sync/master.lua
    make-slave-sync-configs ${ip_file} ${shared_dir}/sync

    cp ${OCSPARK}/tf/target/tf-1.0.0.jar ${shared_dir}/ ||
        abort "copy tf.jar failed"
    cp ${OCSPARK}/bin/runtfserver.sh ${shared_dir}/ ||
        abort "copy runtfserver.sh failed"
    cp ${OCSPARK}/newapp/newapp-arm ${shared_dir}/newapp ||
        abort "copy newapp failed"
    cp ${OCSPARK}/newapp/dummytf.pl ${shared_dir}/ ||
        abort "copy dummytf.pl failed"
    cp ${OCSPARK}/newapp/simulate.pl ${shared_dir}/ ||
        abort "copy simulate.pl failed"
    cp ${OCSPARK}/newapp/test.jpg ${shared_dir}/ ||
        abort "copy test.jpg failed"
    cp ${OCSPARK}/sparcle-1.5-latest/sparcle-client.py ${shared_dir}/ ||
        abort "copy sparcle 1.5 client failed"
    cp ${OCSPARK}/sparcle-1.5-latest/sparcle-server.py ${shared_dir}/ ||
        abort "copy sparcle 1.5 server failed"
    cp -r ${OCSPARK}/realtime_object_detection ${shared_dir}/ ||
        abort "copy odi failed"

    mkdir ${shared_dir}/pointr

    chmod +x ${shared_dir}/runtfserver.sh ||
        abort "can't chmod runtfserver.sh"

    echo "localhost" > ${shared_dir}/conf/hostname ||
        abort "can't create conf/hostname"
}

function make-shared-remote { remote-op make-shared $@; } # experimental

## ----------------------------------------------------------------------------
## Deploy a shared directory (and delete any existing shared directory
## first).  Note: these functions don't propogate down the stack as
## usual because each has to handle tarring up and piping the source
## shared dir and handling the sudo password.
## ----------------------------------------------------------------------------

function deploy-shared {
    local shared_dir=$1

    [ -d ${shared_dir} ] || abort "can't find shared dir"

    tar -cz ${shared_dir} | (cd / && sudo tar -xz) ||
        abort "deployment of shared dir failed"
}

function deploy-shared-to-host {
    local ip=$1
    local shared_dir=$2

    [ -d ${shared_dir} ] || abort "can't find shared dir"

    ## For now, if SHARED_DIR is not "/shared" then abort, so as to make
    ## sure we don't accidentally rm big chunks of the root file system.

    [ "${SHARED_DIR}" != "/shared" ] && abort "unexpected shared dir '${SHARED_DIR}'"

    (stty -echo
     read passwd
     stty echo
     echo $passwd
     cd ${shared_dir}
     tar -cz .) |
        ssh ${ip} "sudo -S bash -c \"rm -rf ${SHARED_DIR} && mkdir -p ${SHARED_DIR} && cd ${SHARED_DIR} && tar -xz\"" ||
        abort "deployment of shared dir failed"
    echo
}

function deploy-shared-to-cluster-host {
    local ip=$1
    local shared_dir=$2
    local passwd=$3

    [ "${shared_dir}" == "" ] && abort "shared dir not specified"
    [ -d ${shared_dir} ] || abort "can't find shared dir"

    ## For now, if SHARED_DIR is not "/shared" then abort, so as to make
    ## sure we don't accidentally rm big chunks of the root file system.

    [ "${SHARED_DIR}" != "/shared" ] && abort "unexpected shared dir '${SHARED_DIR}'"

    (echo $passwd; cd ${shared_dir} && tar -cz .) |
        ssh ${ip} "sudo -S -p '' bash -c \"rm -rf ${SHARED_DIR} && mkdir -p ${SHARED_DIR} && cd ${SHARED_DIR} && tar -xz\"" ||
        abort "deployment of shared dir failed"
}

function deploy-shared-to-cluster {
    local ip_file=$1
    local shared_dir=$2

    echo -n "[sudo] password for ${USER}: "
    stty -echo
    read passwd
    stty echo
    echo
    cluster-op deploy-shared-to-cluster-host deploy-shared-to-cluster-host "${ip_file}" "${shared_dir}" "${passwd}"
}

## ----------------------------------------------------------------------------
## Archive a shared directory.
## ----------------------------------------------------------------------------

## TODO: modify to take sudo password first and then pass on to all hosts.

function archive-shared {
    local shared_dir=$1

    [ -d ${shared_dir} ] || abort "can't find shared dir"

    local target="${ARCHIVE_DIR}/$(mktemp -u shared.XXXXXX)" ||
        abort "creating shared dir archive name failed"

    [ -e ${target} ] && abort "archive shared dir exists"

    sudo mkdir -p ${ARCHIVE_DIR} || abort "creating archive dir failed"
    sudo mv ${SHARED_DIR} ${target} || abort "archiving of shared dir failed"
}

function archive-shared-on-host { remote-op archive-shared "$1"; }

function archive-shared-on-cluster {
    cluster-op archive-shared-on-host archive-shared-on-host "$@"
}

## ----------------------------------------------------------------------------
## Fetch data for analysis.
## ----------------------------------------------------------------------------

function fetch-data {
    local analysis_dir=$1

    [ "${analysis_dir}" == "" ] && abort "no analysis dir specified"
    [ -d ${analysis_dir} ] && abort "specified local data dir already exists"

    mkdir -p ${analysis_dir} || abort "make local data dir failed"

    local stat_file="$(mktemp -u /tmp/output.XXXXXX)"

    (cd ${DATA_DIR}/output && stat -c '%y %n' *.jpg.result > ${stat_file}) ||
        abort "gathering output stats failed"

    cp ${stat_file} ${analysis_dir}/output.stat || abort "copying output stats failed"

    (cd ${DATA_DIR} && tar -cz output/*.result) | (cd ${analysis_dir} && tar -xz) ||
        abort "copying output results failed"

    cp ${LOG_DIR}/simulate ${analysis_dir}/ || abort "copying simulator log failed"
}

function fetch-data-from-master {
    local ip=$1
    local analysis_dir=$2

    [ "${analysis_dir}" == "" ] && abort "no analysis dir specified"
    [ -d ${analysis_dir} ] && abort "specified local data dir already exists"

    mkdir -p ${analysis_dir} || abort "make local data dir failed"

    if [[ "${VERSION}" == "1" ]]; then
        local stat_file="$(mktemp -u /tmp/output.XXXXXX)"

        ssh ${ip} "cd ${DATA_DIR}/output && stat -c '%y %n' *.jpg.result > ${stat_file}" ||
            abort "gathering output stats failed"

        scp ${ip}:${stat_file} ${analysis_dir}/output.stat ||
            abort "copying output stats failed"

        ssh ${ip} "cd ${DATA_DIR} && tar -cz output/*.result" |
            (cd ${analysis_dir} && tar -xz) || abort "copying output results failed"

        scp ${ip}:${LOG_DIR}/simulate ${analysis_dir}/ ||
            abort "copying simulator log failed"
    elif [[ "${VERSION}" == "1.5" ]]; then
        echo "put something here"
    else
        local stat_file="$(mktemp -u /tmp/stats.XXXXXX)"

        ssh ${ip} "cd ${DATA_DIR}/sync && find . -type f -print0 | xargs -0 stat -c '%y %n' > ${stat_file}" ||
            abort "gathering stats failed"

        scp ${ip}:${stat_file} ${analysis_dir}/stats ||
            abort "copying stats failed"

        scp ${ip}:${LOG_DIR}/simulate ${analysis_dir}/ ||
            abort "copying simulator log failed"
    fi
}

function fetch-data-from-cluster {
    local ip_file=$1
    local analysis_dir=$2

    cluster-op fetch-data-from-master "" "${ip_file}" "${analysis_dir}"
}

## ----------------------------------------------------------------------------
## Analyse data.
## ----------------------------------------------------------------------------

function analyse-data {
    local analysis_dir=$1

    [ "${analysis_dir}" == "" ] && abort "no analysis dir specified"
    [ -d ${analysis_dir} ] || abort "can't find local analysis dir"

    (cd ${analysis_dir} && Rscript ${OCSPARK}/newapp/analyse.R) ||
        abort "failed to run Rscript"
}

## ----------------------------------------------------------------------------
## Clean a data directory (but not the output subdirectory).
## ----------------------------------------------------------------------------

function clean-data {
    if [ ! -d ${DATA_DIR} ]; then
        status "no data dir"
        return
    fi

    rm "${DATA_DIR}"/input/*.* 2> /dev/null || true
    rm "${DATA_DIR}"/input/processing/*.* 2> /dev/null || true
    rm -rf "${DATA_DIR}"/input/completed/* 2> /dev/null || true
    rm "${DATA_DIR}"/tmp/*.* 2> /dev/null || true
}

function clean-host-data { remote-op clean-data "$1"; }
function clean-cluster-data { cluster-op clean-host-data clean-host-data "$@"; }

## ----------------------------------------------------------------------------
## Totally clean a data directory (including the output subdirectory)
## ----------------------------------------------------------------------------

function scrub-data {
    if [ ! -d ${DATA_DIR} ]; then
        status "no data dir"
        return
    fi

    if [[ "${VERSION}" == "1" ]]; then
        rm "${DATA_DIR}"/input/*.* 2> /dev/null || true
        rm "${DATA_DIR}"/input/processing/*.* 2> /dev/null || true
        rm -rf "${DATA_DIR}"/input/completed/* 2> /dev/null || true
        rm "${DATA_DIR}"/tmp/*.* 2> /dev/null || true
        rm "${DATA_DIR}"/output/*.* 2> /dev/null || true
    elif [[ "${VERSION}" == "1.5" ]]; then
        rm "${DATA_DIR}"/ingress/*.* 2> /dev/null || true
        rm "${DATA_DIR}"/egress/*.* 2> /dev/null || true
        rm "${DATA_DIR}"/ingress/*/*.* 2> /dev/null || true
        rm "${DATA_DIR}"/egress/*/*.* 2> /dev/null || true
    else
        rm "${DATA_DIR}"/input/*.* 2> /dev/null || true
        rm "${DATA_DIR}"/output/*.* 2> /dev/null || true
        rm -rf "${DATA_DIR}"/sync/* 2> /dev/null || true
        rm "${DATA_DIR}"/ingress/* 2> /dev/null || true
        rm "${DATA_DIR}"/egress/* 2> /dev/null || true
    fi
}

function scrub-host-data { remote-op scrub-data "$1"; }
function scrub-cluster-data { cluster-op scrub-host-data scrub-host-data "$@"; }

## ----------------------------------------------------------------------------
## Clean a log directory.
## ----------------------------------------------------------------------------

function clean-logs {
    if [ ! -d ${DATA_DIR} ]; then
        status "no log dir"
        return
    fi

    rm "${LOG_DIR}/*" || true
}

function clean-host-logs { remote-op clean-logs "$1"; }
function clean-cluster-logs { cluster-op clean-host-logs clean-host-logs "$@"; }

## ----------------------------------------------------------------------------
## Parse command-line arguments.
## ----------------------------------------------------------------------------

POSITIONAL=()
IP=
IP_FILE=
USER_NAME=
OUTPUT_PATH=
DEBUG=
VERSION=1

while [[ $# -gt 0 ]]; do
    case "$1" in
        -h|--host)
            IP="$2"
            shift; shift
            ;;

        -c|--cluster)
            IP_FILE="$2"
            shift; shift
            ;;

        -u|--user)
            USER_NAME="$2"
            shift; shift
            ;;

        -p|--path)
            LOCAL_PATH="$2"
            shift; shift
            ;;

        -d|--debug)
            DEBUG=1
            shift
            ;;

        -v|--version)
            VERSION="$2"
            shift; shift
            ;;

        *)
            POSITIONAL+=("$1")
            shift
            ;;
    esac
done

## Restore the positional args ready to parse normally.

set -- "${POSITIONAL[@]}"

## Ensure legal usage.

if [[ ! -z ${IP} && ! -z ${IP_FILE} ]]; then
    abort "please specify either remote host or cluster file but not both"
fi

if [[ "${VERSION}" != "1" && "${VERSION}" != "1.5" && "${VERSION}" != "2" ]]; then
    abort "version must be 1, 1.5 or 2"
fi

if [[ "${VERSION}" == "1" ]]; then
    DATA_DIR=${DATA_DIR_1}
elif [[ "${VERSION}" == "1.5" ]]; then
    DATA_DIR=${DATA_DIR_1_5}
else
    DATA_DIR=${DATA_DIR_2}
fi

## Parse a command.

function do-command {
    local command=$1;
    
    case $1 in
        identify)
            echo "Identifying hosts..."
            if [ "$IP_FILE" != "" ]; then
                identify-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                identify-host "${IP}"
            else
                identify
            fi
            ;;

        adopt)
            echo "Adopting hosts..."
            if [ "$IP_FILE" != "" ]; then
                adopt-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                adopt-host "${IP}"
            else
                adopt
            fi
            ;;

        authorize)
            echo "Authorizing hosts..."
            if [ "$IP_FILE" != "" ]; then
                authorize-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                authorize-host "${IP}"
            else
                abort "please specify (-h) remote host or (-c) cluster file"
            fi
            ;;

        make-shared)
            ## Don't check for cluster file here because we need it as an argument.
            echo "Making shared directory..."
            if [ "$IP" != "" ]; then
                make-shared-remote "${IP}" "${IP_FILE}" "${LOCAL_PATH}"
            else
                make-shared "${IP_FILE}" "${LOCAL_PATH}"
            fi
            ;;

        deploy-shared)
            echo "Deploying shared directory..."
            if [ "$IP_FILE" != "" ]; then
                deploy-shared-to-cluster "${IP_FILE}" "${LOCAL_PATH}"
            elif [ "$IP" != "" ]; then
                deploy-shared-to-host "${IP}" "${LOCAL_PATH}"
            else
                deploy-shared "${LOCAL_PATH}"
            fi
            ;;

        archive-shared)
            echo "Archiving shared directory..."
            if [ "$IP_FILE" != "" ]; then
                archive-shared-on-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                archive-shared-on-host "${IP}"
            else
                archive-shared
            fi
            ;;

        fetch-data)
            echo "Fetch analysis data..."
            if [ "$IP_FILE" != "" ]; then
                fetch-data-from-cluster "${IP_FILE}" "${LOCAL_PATH}"
            elif [ "$IP" != "" ]; then
                fetch-data-from-master "${IP}" "${LOCAL_PATH}"
            else
                fetch-data "${LOCAL_PATH}"
            fi
            ;;

        analyse-data)
            echo "Analyse data..."
            if [ "$IP_FILE" != "" ]; then
                abort "can't do this on a remote host or cluster"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host or cluster"
            else
                analyse-data "${LOCAL_PATH}"
            fi
            ;;

        setup)
            echo "Setting up hosts..."
            if [ "$IP_FILE" != "" ]; then
                setup-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                setup-host "${IP}"
            else
                setup
            fi
            ;;

        clone)
            echo "Cloning sparcle repository..."
            if [ "$IP_FILE" != "" ]; then
                abort "can't do this on a remote host or cluster"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host or cluster"
            else
                clone
            fi
            ;;

        build)
            echo "Building sparcle..."
            if [ "$IP_FILE" != "" ]; then
                abort "can't do this on a remote host or cluster"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host or cluster"
            else
                build
            fi
            ;;

        package)
            echo "Packing sparcle distribution..."
            if [ "$IP_FILE" != "" ]; then
                abort "can't do this on a remote host or cluster"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host or cluster"
            else
                package
            fi
            ;;

        deploy-app)
            echo "Deploying sparcle distribution..."
            if [ "$IP_FILE" != "" ]; then
                deploy-app-to-cluster "${IP_FILE}" "${LOCAL_PATH}"
            elif [ "$IP" != "" ]; then
                deploy-app-to-host "${IP}" "${LOCAL_PATH}"
            else
                deploy-app "${LOCAL_PATH}"
            fi
            ;;

        clean-data)
            echo "Cleaning data directory..."
            if [ "$IP_FILE" != "" ]; then
                clean-cluster-data "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                clean-host-data "${IP}"
            else
                clean-data
            fi
            ;;

        scrub-data)
            echo "Scrubbing data directory..."
            if [ "$IP_FILE" != "" ]; then
                scrub-cluster-data "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                scrub-host-data "${IP}"
            else
                scrub-data
            fi
            ;;

        clean-logs)
            echo "Cleaning log directory..."
            if [ "$IP_FILE" != "" ]; then
                clean-cluster-logs "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                clean-host-logs "${IP}"
            else
                clean-logs
            fi
            ;;

        start-slave)
            echo "Starting slave(s)..."
            if [ "$IP_FILE" != "" ]; then
                start-cluster-slaves "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                start-remote-slave "${IP}"
            else
                start-slave
            fi
            ;;

        start-master)
            echo "Starting master..."
            if [ "$IP_FILE" != "" ]; then
                start-cluster-masters "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                start-remote-master "${IP}"
            else
                start-master
            fi
            ;;

        start)
            echo "Starting cluster..."
            if [ "$IP_FILE" != "" ]; then
                start-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host.  Please specify (-c) cluster file"
            else
                abort "please specify (-c) cluster file"
            fi
            ;;

        stop-slave)
            echo "Stopping slave(s)..."
            if [ "$IP_FILE" != "" ]; then
                stop-cluster-slaves "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                stop-remote-slave "${IP}"
            else
                stop-slave
            fi
            ;;

        stop-tensorflow)
            echo "Stopping tensorflow(s)..."
            if [ "$IP_FILE" != "" ]; then
                stop-cluster-tensorflows "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                stop-remote-tensorflow "${IP}"
            else
                stop-tensorflow
            fi
            ;;

        stop-master)
            echo "Stopping master..."
            if [ "$IP_FILE" != "" ]; then
                stop-cluster-masters "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                stop-remote-master "${IP}"
            else
                stop-master
            fi
            ;;

        stop)
            echo "Stopping cluster..."
            if [ "$IP_FILE" != "" ]; then
                stop-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host.  Please specify (-c) cluster file"
            else
                abort "please specify (-c) cluster file"
            fi
            ;;

        start-simulator)
            echo "Starting simulator..."
            if [ "$IP_FILE" != "" ]; then
                start-cluster-simulators "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                start-remote-simulator "${IP}"
            else
                start-simulator
            fi
            ;;

        stop-simulator)
            echo "Stopping simulator..."
            if [ "$IP_FILE" != "" ]; then
                stop-cluster-simulators "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                stop-remote-simulator "${IP}"
            else
                stop-simulator
            fi
            ;;

        monitor-slave)
            echo "Starting slave monitor..."
            if [ "$IP_FILE" != "" ]; then
                monitor-cluster-slaves "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                monitor-remote-slave "${IP}"
            else
                monitor-slave
            fi
            ;;

        monitor-master)
            echo "Starting master monitor..."
            if [ "$IP_FILE" != "" ]; then
                monitor-cluster-masters "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                monitor-remote-master "${IP}"
            else
                monitor-master
            fi
            ;;

        monitor)
            echo "Starting cluster monitor..."
            if [ "$IP_FILE" != "" ]; then
                monitor-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host.  Please specify (-c) cluster file"
            else
                abort "please specify (-c) cluster file"
            fi
            ;;

        *)
            abort "Unexpected or no task specified (expecting 'identify', 'adopt', 'authorize', 'shared', 'deploy-shared', 'setup', 'clone', 'build', 'package', 'deploy-app', 'start-slave', 'start-master', 'start', 'stop-slave', 'stop-master', 'stop')"
            ;;
    esac
}


## ----------------------------------------------------------------------------
## Entry point.
## ----------------------------------------------------------------------------

for command in $@; do
    do-command $command
done

