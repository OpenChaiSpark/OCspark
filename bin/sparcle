#!/bin/bash

LOG_DIR=/sparcle-logs
ARCHIVE_DIR=/sparcle-archive
DIST_DIR=/sparcle-dist
SHARED_DIR=/shared
BASE_SLAVE_PORT=61230
#DATA_DIR=/home/mike/tmp/ocspark
DATA_DIR=/data
APP_NAME=test-local
GPU_REGISTRY_PORT=60001
DEBUG=1

#OCSPARKDIR=${HOME}/src
#OCSPARKDIR=${HOME}/work/pointr/src
#OCSPARKNAME=OCspark
#OCSPARK=${OCSPARKDIR}/${DISTNAME}

OCSPARK="$(cd "$(dirname "$(dirname "${BASH_SOURCE[0]}")")" > /dev/null && pwd)"
OCSPARKNAME="$(basename "${OCSPARK}")"
OCSPARKDIR="$(dirname "${OCSPARK}")"

## We assume we don't have to build here because it's the same arch as
## the build server.  However we do install (most of) the build tools
## since we might need them later.  Note: this follows bin/setupXgene.sh.

## Note: apt-get is idempotent so we don't have to check if a package
## is already installed before installing it.

## ----------------------------------------------------------------------------
## Infer the architecture and make sure it's recognized.
## ----------------------------------------------------------------------------

ARCH=$(uname -m)

if [ "${ARCH}" != "x86_64" ] && [ "${ARCH}" != "ARM" ]; then
    abort "Unexpected architecture inferred (expecting 'arch_64')"
fi


## ----------------------------------------------------------------------------
## Reportng.
## ----------------------------------------------------------------------------

function status { echo "$1." 1>&2; }
function abort { status "Aborting: $1"; exit 1; }

## ----------------------------------------------------------------------------
## Apply a function on another host (specified by IP).  Note: we
## hardcode USER in the ssh call because we might be using it in a
## declared function (eg. adopt-host) and don't want the function to
## use the remote value of USER (eg. nvidia).
## ----------------------------------------------------------------------------

function remote-op {
    callback=$1
    remote_host=$2
    user=$3

    [ "${remote_host}" == "" ] && abort "No remote host (ip addresses) supplied"

    if [ "${user}" != "" ]; then
        ssh ${user}@${remote_host}\
            -t "$(declare -f status abort create-dirs ${callback}); USER=${USER}; ARCHIVE_DIR=${ARCHIVE_DIR}; LOG_DIR=${LOG_DIR}; DIST_DIR=${DIST_DIR}; SHARED_DIR=${SHARED_DIR}; DATA_DIR=${DATA_DIR}; ${callback}" ||
            abort "remote command failed"
    else
        ssh ${remote_host}\
            -t "$(declare -f status abort create-dirs ${callback}); USER=${USER}; ARCHIVE_DIR=${ARCHIVE_DIR}; LOG_DIR=${LOG_DIR}; DIST_DIR=${DIST_DIR}; SHARED_DIR=${SHARED_DIR}; DATA_DIR=${DATA_DIR}; ${callback}" ||
            abort "remote command failed"
    fi
}

## ----------------------------------------------------------------------------
## Apply a function to all hosts in an IP file (can contain multiple
## slaves and/or one (at most) master).  Note: we use FD 3 in the
## while read (instead of stdin) to prevent ssh from slurping the
## whole of the input file on its first invocation.  (Alternatively we
## could use "ssh -n" in remote-op() but that would prevent us from
## using remote-op to send data to the remote hosts (eg. public keys,
## tarballs), so using a different FD in the read avoids the slurping
## problem and allows us to pass stdin through ssh when we want to.
## Note: we need to operate on the master last (after all the slave)
## if if we're starting services, but for now we'll just make sure the
## master appears at the end of the cluster definition file.
## ----------------------------------------------------------------------------

function cluster-op {
    master_callback=$1; shift
    slave_callback=$1; shift
    ip_file=$1; shift

    [ "${ip_file}" == "" ] && abort "No IP file supplied"
    [ -e ${ip_file} ] || abort "Supplied IP file '${ip_file}' not found"

    got_master="no"

    while read -u 3 -r line; do
        ip=$(echo $line | cut -f1 -d " ")
        class=$(echo $line | cut -f2 -d " ")

        echo "Processing ${class}: ${ip}" 1>&2

        if [ "${class}" == "slave" ]; then
            [ "${slave_callback}" != "" ] && ${slave_callback} ${ip} "$@"
        elif [ "${class}" == "master" ]; then
            [ "got_master" == "yes" ] &&\
                abort "Found more than one master in supplied IP file '${ip_file}'"

            got_master="yes"

            ## We sleep briefly before calling the master callback
            ## because if we're launching services then we appear to
            ## need to make sure that all the slaves are fully up
            ## before the master starts.

            sleep 5

            [ "${master_callback}" != "" ] && ${master_callback} ${ip} "$@"
        else
            abort "Found unexpected host class '${class}' in supplied IP file '${ip_file}' (expecting 'slave' or 'master')"
        fi
    done 3< <(cat ${ip_file} | egrep -v "^#")
}

function background-cluster-op {
    master_callback=$1; shift
    slave_callback=$1; shift
    ip_file=$1; shift

    [ "${ip_file}" == "" ] && abort "No IP file supplied"
    [ -e ${ip_file} ] || abort "Supplied IP file '${ip_file}' not found"

    got_master="no"

    while read -u 3 -r line; do
        ip=$(echo $line | cut -f1 -d " ")
        class=$(echo $line | cut -f2 -d " ")

        echo "Processing ${class}: ${ip}" 1>&2

        if [ "${class}" == "slave" ]; then
            [ "${slave_callback}" != "" ] && ${slave_callback} ${ip} "$@" &
        elif [ "${class}" == "master" ]; then
            [ "got_master" == "yes" ] &&\
                abort "Found more than one master in supplied IP file '${ip_file}'"

            got_master="yes"

            [ "${master_callback}" != "" ] && ${master_callback} ${ip} "$@" &
        else
            abort "Found unexpected host class '${class}' in supplied IP file '${ip_file}' (expecting 'slave' or 'master')"
        fi
    done 3< <(cat ${ip_file} | egrep -v "^#")

    trap 'exit' INT TERM
    trap 'kill 0' EXIT

    wait $(jobs -pr)
}

## ----------------------------------------------------------------------------
## Add a personal user on the specified host.  Uses the 'nvidia'
## (sudo) account to access the host in order to add the new account.
## ----------------------------------------------------------------------------

## Note: possible approaches to eliminating the need for the user
## interaction and multiple password entries:
##
##  See: https://serverfault.com/questions/841831/ssh-ask-password-once-reuse-password-until-timeout-finishes
##
##    sshpass
##    expect
##    ssh -o ControlPath...

## Need to make ${USER} evaluate to mike (ie. im the local shell
## *before* the function is declared and invoked by the remote shell).

function adopt {
    sudo adduser ${USER} || abort "adduser failed"
    sudo usermod -aG sudo ${USER} || abort "usermod failed"
}

function adopt-host { remote-op adopt $1 nvidia; }
function adopt-cluster { cluster-op adopt-host adopt-host $@; }

## ----------------------------------------------------------------------------
## Identify a host.
## ----------------------------------------------------------------------------

function identify {
    uname -a;
    df -h .
}

function identify-host { remote-op identify $1; }
function identify-cluster { cluster-op identify-host identify-host $@; }

## ----------------------------------------------------------------------------
## Add public ssh keys to new user on the specified host.
## ----------------------------------------------------------------------------

function authorize {
    mkdir -p ${HOME}/.ssh || abort "make ssh dir failed"
    cat >> ${HOME}/.ssh/authorized_keys || abort "append ssh keys failed"
}

function authorize-host {
    [ -e "${HOME}/.ssh/id_dsa.pub" ] || abort "No DSA public key found"
    [ -e "${HOME}/.ssh/id_rsa.pub" ] || abort "No RSA public key found"

    cat ${HOME}/.ssh/id_dsa.pub ${HOME}/.ssh/id_rsa.pub | remote-op authorize $1
}

function authorize-cluster { cluster-op authorize-host authorize-host $@; }

## ----------------------------------------------------------------------------
## Install packages for a worker (runtime only).
## ----------------------------------------------------------------------------

## Let's remove the apt-get update for now since it's failing.  Let's
## also skip installing screen since we don't need it yet.  Note: the
## oracle java installer only seems to be available for TX2s.

function setup {
    ## Set up java.

    sudo add-apt-repository ppa:webupd8team/java || abort "set java repo failed"
    sudo dpkg --configure -a || abort "dpkg configure failed"
    sudo apt-get update || abort "update failed"
    sudo apt-get install -y oracle-java8-installer || abort "install java failed"
    sudo apt-get install -y oracle-java8-set-default || abort "set default failed"

    ## Set up misc other packages.

##    sudo apt-get install -y screen || abort "install screen failed"
    sudo apt-get install -y software-properties-common ||
        abort "install common properties failed"
}

function setup-host { remote-op setup $1; }
function setup-cluster { cluster-op setup-host setup-host $@; }

## ----------------------------------------------------------------------------
## Install packages for a build server.
## ----------------------------------------------------------------------------

function setup-for-building {
    ## Set up java.

    sudo add-apt-repository ppa:webupd8team/java || abort "set java repo failed"
    sudo apt-get update || abort "update failed"
    sudo apt-get install -y oracle-java8-installer || abort "install java failed"
    sudo apt-get install -y oracle-java8-set-default || abort "set default failed"

    ## Set up scala.

    sudo wget www.scala-lang.org/files/archive/scala-2.11.8.deb ||
        abort "fetch scala failed"
    sudo dpkg -i scala-2.11.8.deb || abort "install scala failed"

    ## Set up misc other packages.

    sudo apt-get install -y screen || abort "install screen failed"
    sudo apt get install -y software-properties-common ||
        abort "install common properties failed"

    ## Set up maven.

    sudo apt-add-repository universe || abort "add universe repo failed"
    sudo apt-get update || abort "update failed"
    sudo apt-get install -y maven || abort "install maven failed"

    ## Set up yq.  Note: not needed any more.

##    sudo add-apt-repository ppa:rmescandon/yq || abort "add yq repo failed"
##    sudo apt update || abort "update failed"
##    sudo apt install -y yq || abort "install yq failed"
}

function setup-host-for-building { remote-op setup-for-building $1; }

## ----------------------------------------------------------------------------
## Create a clone of the sparcle repo.
## ----------------------------------------------------------------------------

function clone {
    (cd ${HOME} && mkdir -p ${OCSPARKDIR}) || abort "mkdir failed"
    (cd ${OCSPARKDIR} && git clone https://github.com/OpenChaiSpark/OCspark.git) ||
        abort "git clone failed"
    (cd ${OCSPARK} && git checkout -b v3 origin/v3) || abort "git branch failed"
    (cd ${OCSPARK} && git pull) || abort "git pull failed"
}

function remote-clone { remote-op clone $1; }

## ----------------------------------------------------------------------------
## Build.
## ----------------------------------------------------------------------------

## Note: there is apparently a circular dependency: you have to do
## some combination of "./bin/buildtf.arm.sh", "(cd tfdma;
## ./build.arm.sh)" and "mvn package", in some order, in order to get
## "./bin/buildtf.arm.sh" building properly.
##
## Need to add some include paths for gcc:
##
##   For jni.h:     /usr/lib/jvm/java-8-oracle/include
##   For jni_md.h:  /usr/lib/jvm/java-8-oracle/include/linux
##   Other headers: /usr/include
##   Other headers: /usr/include/linux
##   Other headers: /usr/local/include

function build {
    export CPATH=/usr/lib/jvm/java-8-oracle/include:/usr/lib/jvm/java-8-oracle/include/linux:/usr/include:/usr/include/linux:/usr/local/include
    export GITDIR=${OCSPARK}
    (cd ${GITDIR} && mvn install && ./bin/buildtf.arm.sh) ||
        abort "git maven build failed"
    (cd ${GITDIR}/newapp && make) || abort "git make newapp failed"
}

function remote-build { remote-op build $1; }

## ----------------------------------------------------------------------------
## Create a sparcle package (tarball) ready to deploy to remote hosts.
## ----------------------------------------------------------------------------

function package {
    (cd ${OCSPARKDIR} && tar czvf ${HOME}/ocspark-${ARCH}.tgz ${OCSPARKNAME}) ||
        abort "create package failed"
}

function remote-package { remote-op package $1; }

## ----------------------------------------------------------------------------
## Deploy an OCspark directory.
## ----------------------------------------------------------------------------

function deploy-app {
    app_dir=$1

    [ -d ${app_dir} ] || abort "can't find app dir"

    parent_dir=$(dirname ${app_dir})
    target_dir=$(basename ${app_dir})

    [ -d ${HOME}/${target_dir} ] && abort "app dir already deployed"

    (cd $parent_dir && tar -cz ${target_dir}) | (cd && tar -xz) ||
        abort "deployment of app dir failed"
}

function deploy-app-to-host {
    ip=$1
    app_dir=$2

    [ -d ${app_dir} ] || abort "can't find app dir"

    parent_dir=$(dirname ${app_dir})
    target_dir=$(basename ${app_dir})

    ssh ${ip} "ls -d ${target_dir} > /dev/null 2>&1" &&
        abort "Remote sparcle already present"

    (cd ${parent_dir} && tar -cz ${target_dir}) | ssh ${ip} "tar -xz" ||
        abort "deployment of app dir failed"
}

function deploy-app-to-cluster {
    ip_file=$1
    app_dir=$2

    cluster-op deploy-app-to-host deploy-app-to-host "${ip_file}" "${app_dir}"
}

## ----------------------------------------------------------------------------
## Start a slave (typically on a GPU).  Note: slaves must be started
## before the master.  Note: we must call "set -m" to prevent the
## discconnection of the tty (created by "ssh -t") from killing the
## slave process (even thought it's nohup'd).  Note: we wrap the IP
## extraction in an echo to trim whitespace.
## ----------------------------------------------------------------------------

function create-dirs {
    ## Create the log dir if necessary.

    if [ ! -d "${LOG_DIR}" ]; then
        sudo mkdir -p "${LOG_DIR}" || abort "creating log dir failed"
        sudo chmod a+rwx "${LOG_DIR}" || abort "setting log dir permissions failed"
    fi

    ## Create the data dir if necessary.

    if [ ! -d "${DATA_DIR}" ]; then
        sudo mkdir -p "${DATA_DIR}/input" || abort "creating input dir failed"
        sudo mkdir -p "${DATA_DIR}/output" || abort "creating output dir failed"
        sudo mkdir -p "${DATA_DIR}/tmp" || abort "creating tmp dir failed"
        sudo chmod -R a+rwx "${DATA_DIR}" || abort "setting data dir permissions failed"
    fi
}

function start-slave {
    local log_ext="$(mktemp -u XXXXXX)" || abort "creating slave log extension failed"
    local ip=$(echo $(hostname -I)) || abort "querying hostname failed"
    local port=$(fgrep ${ip} ${SHARED_DIR}/gpu-slaves.txt |
                     cut -f2 -d" " | cut -f2 -d:) ||
        abort "inferring port from ip address failed"

    ## Make sure there are no existing slave processes running.

    if (pgrep -f "^java .+ -jar ${SHARED_DIR}/tf" > /dev/null); then
        status "slave already running"
    else
        create-dirs

        ## Archive the old log file if present.

        local log_file="${LOG_DIR}/slave"

        if [[ -e "${log_file}" ]]; then
            mv "${log_file}" "${log_file}.${log_ext}" ||
                abort "archiving old slave log file ${log_file} failed"
        fi

        ## Start the slave and dummy tensorflow processes.

        set -m

        nohup ${SHARED_DIR}/runtfserver.sh localhost ${port} > ${log_file} 2>&1 ||
            abort "starting slave on ip ${ip} port ${port} failed" &
        status "started slave on ip ${ip} port ${port}"
    fi

    if (pgrep -f "^/usr/bin/perl /shared/dummytf.pl ${DATA_DIR}" > /dev/null); then
        status "dummytf already running"
    else
        create-dirs

        ## Archive the old log file if present.

        local dummy_log_file="${LOG_DIR}/dummytf"

        if [[ -e "${dummy_log_file}" ]]; then
            mv "${dummy_log_file}" "${dummy_log_file}.${log_ext}" ||
                abort "archiving old dummytf log file ${dummy_log_file} failed"
        fi

        ## Start the slave and dummy tensorflow processes.

        set -m

        nohup ${SHARED_DIR}/dummytf.pl "${DATA_DIR}" > ${dummy_log_file} 2>&1 ||
            abort "starting dummytf on ip ${ip} failed" &
        status "started dummytf on ip ${ip} port ${port}"
    fi
}

function start-remote-slave { remote-op start-slave $1; }
function start-cluster-slaves { cluster-op "" start-remote-slave $@; }

## ----------------------------------------------------------------------------
## Stop a slave on a remote host (typically a GPU).  Note: we match
## java as the start of the string in order to avoid matching the
## pkill command itself.  Note: we make this idempotent by ignoring an
## error condition.
## ----------------------------------------------------------------------------

function stop-slave {
    local slave_pattern="^java .+ -jar ${SHARED_DIR}/tf"

    if (pgrep -f "${slave_pattern}" > /dev/null); then
        pkill -f "${slave_pattern}" || abort "killing slave failed"
        status "killed slave"
    else
        status "slave already stopped"
    fi

    local dummy_pattern="^/usr/bin/perl /shared/dummytf.pl ${DATA_DIR}"

    if (pgrep -f "${dummy_pattern}" > /dev/null); then
        pkill -f "${dummy_pattern}" || abort "killing slave failed"
        status "killed dummytf"
    else
        status "dummtf already stopped"
    fi
}

function stop-remote-slave { remote-op stop-slave $1; }
function stop-cluster-slaves { cluster-op "" stop-remote-slave $@; }

## ----------------------------------------------------------------------------
## Start a master (eg. on x-gene or i3).
## ----------------------------------------------------------------------------

function start-master {
    ## Make sure there are no existing slave processes running.

    local pattern="^java .+ org.openchai.tensorflow.DirectSubmitter"

    if (pgrep -f "${pattern}" > /dev/null); then
        status "master already running"
        return
    fi

    ## Create the log dir if necessary.

    if [[ ! -d "${LOG_DIR}" ]]; then
        sudo mkdir -p "${LOG_DIR}" || abort "creating log dir failed"
        sudo chmod a+rwx "${LOG_DIR}" || abort "setting log dir permissions failed"
    fi

    ## Create the data dir if necessary.

    if [ ! -d "${DATA_DIR}" ]; then
        sudo mkdir -p "${DATA_DIR}/input" || abort "creating input dir failed"
        sudo mkdir -p "${DATA_DIR}/output" || abort "creating output dir failed"
        sudo mkdir -p "${DATA_DIR}/tmp" || abort "creating tmp dir failed"
        sudo chmod -R a+rwx "${DATA_DIR}" || abort "setting data dir permissions failed"
    fi

    ## Archive the old log file if present.

    local log_ext="$(mktemp -u XXXXXX)" || abort "creating master log extension failed"
    local log_file="${LOG_DIR}/master"

    if [[ -e "${log_file}" ]]; then
        mv "${log_file}" "${log_file}.${log_ext}" ||
            abort "archiving old master log file ${log_file} failed"
    fi

    ## Make sure the IP address matches the config.
    
    local ip=$(echo $(hostname -I)) || abort "querying hostname failed"
    local registry_ip=$(echo $(fgrep gpuRegistryHost ${SHARED_DIR}/conf/apps-config.yml | cut -f2 -d:))

    [[ "${ip}" != "${registry_ip}" ]] &&
        abort "host ip <${ip}> does not match gpu registry ip <${registry_ip}>"

    ## Start the master.

    set -m

    export GITDIR=${DIST_DIR}
    nohup java -Xmx2048m -Dlogger.level=2 -classpath ${DIST_DIR}/tf/target/classes:${DIST_DIR}/tf/libs/* -Djava.net.preferIPv4Stack=true org.openchai.tensorflow.DirectSubmitter ${SHARED_DIR}/conf/submitter.yml > ${log_file} 2>&1 ||
        abort "starting master on ip ${ip} failed" &
    status "started master on ip ${ip}"
}

function start-remote-master { remote-op start-master $1; }
function start-cluster-masters { cluster-op start-remote-master "" $@; }

## ----------------------------------------------------------------------------
## Stop a master on a remote host.
## ----------------------------------------------------------------------------

function stop-master {
    local pattern="^java .+ org.openchai.tensorflow.DirectSubmitter"

    if (pgrep -f "${pattern}" > /dev/null); then
        pkill -f "${pattern}" || abort "killing master failed"
        status "killed master"
    else
        status "master already stopped"
    fi
}

function stop-remote-master { remote-op stop-master $1; }
function stop-cluster-masters { cluster-op stop-remote-master "" $@; }

## ----------------------------------------------------------------------------
## Wrap the remote cluster operation.
## ----------------------------------------------------------------------------

function start-cluster { cluster-op start-remote-master start-remote-slave $@; }
function stop-cluster { cluster-op stop-remote-master stop-remote-slave $@; }

## ----------------------------------------------------------------------------
## Start a simulate process on the master.
## ----------------------------------------------------------------------------

function start-simulator {
    ## Make sure there are no existing simulator processes running.

    local pattern="^/usr/bin/perl simulate.pl"

    if (pgrep -f "${pattern}" > /dev/null); then
        status "simulator already running"
        return
    fi

    ## Create the log dir if necessary.

    if [[ ! -d "${LOG_DIR}" ]]; then
        sudo mkdir -p "${LOG_DIR}" || abort "creating log dir failed"
        sudo chmod a+rwx "${LOG_DIR}" || abort "setting log dir permissions failed"
    fi

    ## Create the data dir if necessary.

    if [ ! -d "${DATA_DIR}" ]; then
        sudo mkdir -p "${DATA_DIR}/input" || abort "creating input dir failed"
        sudo mkdir -p "${DATA_DIR}/output" || abort "creating output dir failed"
        sudo mkdir -p "${DATA_DIR}/tmp" || abort "creating tmp dir failed"
        sudo chmod -R a+rwx "${DATA_DIR}" || abort "setting data dir permissions failed"
    fi

    ## Archive the old log file if present.

    local log_ext="$(mktemp -u XXXXXX)" || abort "creating simulator log extension failed"
    local log_file="${LOG_DIR}/simulate"

    if [[ -e "${log_file}" ]]; then
        mv "${log_file}" "${log_file}.${log_ext}" ||
            abort "archiving old simulator log file ${log_file} failed"
    fi

    ## Make sure the IP address matches the config.

    local ip=$(echo $(hostname -I)) || abort "querying hostname failed"
    local registry_ip=$(echo $(fgrep gpuRegistryHost ${SHARED_DIR}/conf/apps-config.yml | cut -f2 -d:))

    [[ "${ip}" != "${registry_ip}" ]] &&
        abort "host ip <${ip}> does not match gpu registry ip <${registry_ip}>"

    ## Start the simulator.

    set -m

    export GITDIR=${DIST_DIR}
    nohup ${SHARED_DIR}/simulate.pl "${DATA_DIR}" > ${log_file} 2>&1 ||
        abort "starting simulator on ip ${ip} failed" &
    status "started simulator on ip ${ip}"
}

function start-remote-simulator { remote-op start-simulator $1; }
function start-cluster-simulators { cluster-op start-remote-simulator "" $@; }

## ----------------------------------------------------------------------------
## Stop a simulate process on a remote host.
## ----------------------------------------------------------------------------

function stop-simulator {
    local pattern="^/usr/bin/perl /shared/simulate.pl"

    if (pgrep -f "${pattern}" > /dev/null); then
        pkill -f "${pattern}" || abort "killing simulator failed"
        status "killed simulator"
    else
        status "simulator already stopped"
    fi
}

function stop-remote-simulator { remote-op stop-simulator $1; }
function stop-cluster-simulators { cluster-op stop-remote-simulator "" $@; }

## ----------------------------------------------------------------------------
## Tail slave log files.  Try "tail -fv" first to force a hedaer even
## for a single file, then faillback to "tail -f" if necessary.
## ----------------------------------------------------------------------------

#(ssh cpu tail -vf /sparcle-logs/master & ssh gpu-4 tail -vf /sparcleogs/slave /sparcle-logs/dummytf)

function monitor-slave {
    tail -fv "${LOG_DIR}/slave" "${LOG_DIR}/dummytf" 2> /dev/null ||
        tail -f "${LOG_DIR}/slave" "${LOG_DIR}/dummytf" 2> /dev/null
}

function monitor-remote-slave { remote-op monitor-slave $1; }
function monitor-cluster-slaves { background-cluster-op "" monitor-remote-slave $@; }

## ----------------------------------------------------------------------------
## Tail master log files.  Try "tail -fv" first to force a hedaer even
## for a single file, then faillback to "tail -f" if necessary.
## ----------------------------------------------------------------------------

function monitor-master {
    tail -fv "${LOG_DIR}/master" "${LOG_DIR}/simulator" 2> /dev/null ||
        tail -f "${LOG_DIR}/master" "${LOG_DIR}/simulator" 2> /dev/null
}

function monitor-remote-master { remote-op monitor-master $1; }
function monitor-cluster-masters { background-cluster-op monitor-remote-master "" $@; }

## ----------------------------------------------------------------------------
## Tail all log files.
## ----------------------------------------------------------------------------

function monitor-cluster {
    background-cluster-op monitor-remote-master monitor-remote-slave $@
}

## ----------------------------------------------------------------------------
## Create a gpu-slaves.txt file.  Note: we increment a local
## slave_number variable to assign ports.
## ----------------------------------------------------------------------------

declare -i slave_count
declare -i slave_port_offset

function make-gpu-slaves-entry {
    ip=$1

    port=$((${BASE_SLAVE_PORT} + ${slave_port_offset}))
    slave_port_offset=$((${slave_port_offset} + 10))
    slave_count=$((${slave_count} + 1))

    echo "${slave_count} ${ip}:${port} ${APP_NAME} ${DATA_DIR}/input ${DATA_DIR}/output"
}

function make-gpu-slaves {
    ip_file=$1
    output_file=$2

    [ -e ${output_file} ] && abort "gpu-slaves file already exists"

    echo "Making gpu-slaves file" 1>&2

    slave_count=0
    slave_port_offset=0

    cluster-op "" make-gpu-slaves-entry "${ip_file}" > ${output_file}
}

## ----------------------------------------------------------------------------
## Create a submitter.yml file.  Based on
## tf/target/classes/submitter.yml.
## ----------------------------------------------------------------------------

## TODO: could replace the cat with calls to yq.
## TODO: make sure we actually need this (it's passed to java as an argument
## to start the master, but the tests on the lab machines didn't have it and
## worked anyway.

function make-submitter-master {
    ip=$1

    cat << EOF
map:
  main :
    appType: direct
    imageExtensions:
      - jpg
      - jpeg
      - png
      - gif
      - svg
      - tiff
      - mpg
    batchSize: 2
    gpuRegistryHost: ${ip}
    gpuRegistryPort: "${GPU_REGISTRY_PORT}"
EOF
}

function make-submitter {
    ip_file=$1
    output_file=$2

    [ -e ${output_file} ] && abort "submitter file already exists"

    echo "Making submitter file" 1>&2

    cluster-op make-submitter-master "" "${ip_file}" > ${output_file}
}

## ----------------------------------------------------------------------------
## Create an apps-config.yml file.
## ----------------------------------------------------------------------------

## TODO: could replace the cat with calls to yq.

function make-apps-config-master {
    ip=$1

    cat << EOF
connections:
  gpuRegistryHost: ${ip}
  gpuRegistryPort: "${GPU_REGISTRY_PORT}"
defaults:
  apps:
    ${APP_NAME}:
      cmdline: '${SHARED_DIR}/newapp \${1} '
      rundir: \${POINTR_HOME}
      tmpdir: ${DATA_DIR}/tmp
environments:
  linux:
    env:
      POINTR_HOME: ${SHARED_DIR}/pointr
      TENSORFLOW_HOME: /home/ubuntu/tensorflow
      DARKNET_HOME: /git/darknet
      TF_CPP_MIN_LOG_LEVEL: "2"
  osx:
    env:
      POINTR_HOME: /tmp
      TENSORFLOW_HOME: /tmp
      DARKNET_HOME: /tmp
      TF_CPP_MIN_LOG_LEVEL: "2"
EOF
}

function make-apps-config {
    ip_file=$1
    output_file=$2

    [ -e ${output_file} ] && abort "apps-config file already exists"

    echo "Making apps-config file" 1>&2

    cluster-op make-apps-config-master "" "${ip_file}" > ${output_file}
}

## ----------------------------------------------------------------------------
## Create a shared directory (tarball) ready for deployment.
## ----------------------------------------------------------------------------

function make-shared {
    ip_file=$1
    shared_dir=$2

    [ "${shared_dir}" == "" ] && abort "shared dir not specified"

    mkdir -p ${shared_dir}/conf || abort "can't make shared directory"

    make-gpu-slaves ${ip_file} ${shared_dir}/gpu-slaves.txt
    make-apps-config ${ip_file} ${shared_dir}/conf/apps-config.yml
    make-submitter ${ip_file} ${shared_dir}/conf/submitter.yml

    cp ${OCSPARK}/tf/target/tf-1.0.0.jar ${shared_dir}/ ||
        abort "copy tf.jar failed"
    cp ${OCSPARK}/bin/runtfserver.sh ${shared_dir}/ ||
        abort "copy runtfserver.sh failed"
    cp ${OCSPARK}/newapp/newapp-arm ${shared_dir}/newapp ||
        abort "copy newapp failed"
    cp ${OCSPARK}/newapp/dummytf.pl ${shared_dir}/ ||
        abort "copy dummytf.pl failed"
    cp ${OCSPARK}/newapp/simulate.pl ${shared_dir}/ ||
        abort "copy simulate.pl failed"
    cp ${OCSPARK}/newapp/test.jpg ${shared_dir}/ ||
        abort "copy test.jpg failed"

    mkdir ${shared_dir}/pointr

    chmod +x ${shared_dir}/runtfserver.sh ||
        abort "can't chmod runtfserver.sh"

    echo "localhost" > ${shared_dir}/conf/hostname ||
        abort "can't create conf/hostname"
}

function make-shared-remote { remote-op make-shared $@; } # experimental

## ----------------------------------------------------------------------------
## Deploy a shared directory (and delete any existing shared directory
## first).  Note: these functions don't propogate down the stack as
## usual because each has to handle tarring up and piping the source
## shared dir and handling the sudo password.
## ----------------------------------------------------------------------------

function deploy-shared {
    local shared_dir=$1

    [ -d ${shared_dir} ] || abort "can't find shared dir"

    tar -cz ${shared_dir} | (cd / && sudo tar -xz) ||
        abort "deployment of shared dir failed"
}

function deploy-shared-to-host {
    local ip=$1
    local shared_dir=$2

    [ -d ${shared_dir} ] || abort "can't find shared dir"

    ## For now, if SHARED_DIR is not "/shared" then abort, so as to make
    ## sure we don't accidentally rm big chunks of the root file system.

    [ "${SHARED_DIR}" != "/shared" ] && abort "unexpected shared dir '${SHARED_DIR}'"

    (stty -echo
     read passwd
     stty echo
     echo $passwd
     cd ${shared_dir}
     tar -cz .) |
        ssh ${ip} "sudo -S bash -c \"rm -rf ${SHARED_DIR} && mkdir -p ${SHARED_DIR} && cd ${SHARED_DIR} && tar -xz\"" ||
        abort "deployment of shared dir failed"
    echo
}

function deploy-shared-to-cluster-host {
    local ip=$1
    local shared_dir=$2
    local passwd=$3

    [ -d ${shared_dir} ] || abort "can't find shared dir"

    ## For now, if SHARED_DIR is not "/shared" then abort, so as to make
    ## sure we don't accidentally rm big chunks of the root file system.

    [ "${SHARED_DIR}" != "/shared" ] && abort "unexpected shared dir '${SHARED_DIR}'"

    (echo $passwd; cd ${shared_dir} && tar -cz .) |
        ssh ${ip} "sudo -S -p '' bash -c \"rm -rf ${SHARED_DIR} && mkdir -p ${SHARED_DIR} && cd ${SHARED_DIR} && tar -xz\"" ||
        abort "deployment of shared dir failed"
}

function deploy-shared-to-cluster {
    local ip_file=$1
    local shared_dir=$2

    echo -n "[sudo] password for ${USER}: "
    stty -echo
    read passwd
    stty echo
    echo
    cluster-op deploy-shared-to-cluster-host deploy-shared-to-cluster-host "${ip_file}" "${shared_dir}" "${passwd}"
}

## ----------------------------------------------------------------------------
## Archive a shared directory.
## ----------------------------------------------------------------------------

## TODO: modify to take sudo password first and then pass on to all hosts.

function archive-shared {
    local shared_dir=$1

    [ -d ${shared_dir} ] || abort "can't find shared dir"

    local target="${ARCHIVE_DIR}/$(mktemp -u shared.XXXXXX)" ||
        abort "creating shared dir archive name failed"

    [ -e ${target} ] && abort "archive shared dir exists"

    sudo mkdir -p ${ARCHIVE_DIR} || abort "creating archive dir failed"
    sudo mv ${SHARED_DIR} ${target} || abort "archiving of shared dir failed"
}

function archive-shared-on-host { remote-op archive-shared "$1"; }

function archive-shared-on-cluster {
    cluster-op archive-shared-on-host archive-shared-on-host "$@"
}

## ----------------------------------------------------------------------------
## Clean a data directory (but not the output subdirectory).
## ----------------------------------------------------------------------------

function clean-data {
    if [ ! -d ${DATA_DIR} ]; then
        status "no data dir"
        return
    fi

    rm "${DATA_DIR}"/input/*.* 2> /dev/null || true
    rm "${DATA_DIR}"/input/processing/*.* 2> /dev/null || true
    rm -rf "${DATA_DIR}"/input/completed/* 2> /dev/null || true
    rm "${DATA_DIR}"/tmp/*.* 2> /dev/null || true
}

function clean-host-data { remote-op clean-data "$1"; }
function clean-cluster-data { cluster-op clean-host-data clean-host-data "$@"; }

## ----------------------------------------------------------------------------
## Totally clean a data directory (including the output subdirectory)
## ----------------------------------------------------------------------------

function scrub-data {
    if [ ! -d ${DATA_DIR} ]; then
        status "no data dir"
        return
    fi

    rm "${DATA_DIR}"/input/*.* 2> /dev/null || true
    rm "${DATA_DIR}"/input/processing/*.* 2> /dev/null || true
    rm -rf "${DATA_DIR}"/input/completed/* 2> /dev/null || true
    rm "${DATA_DIR}"/tmp/*.* 2> /dev/null || true
    rm -rf "${DATA_DIR}"/output/* 2> /dev/null || true
}

function scrub-host-data { remote-op scrub-data "$1"; }
function scrub-cluster-data { cluster-op scrub-host-data scrub-host-data "$@"; }

## ----------------------------------------------------------------------------
## Clean a log directory.
## ----------------------------------------------------------------------------

function clean-logs {
    if [ ! -d ${DATA_DIR} ]; then
        status "no log dir"
        return
    fi

    rm "${LOG_DIR}/*" || true
}

function clean-host-logs { remote-op clean-logs "$1"; }
function clean-cluster-logs { cluster-op clean-host-logs clean-host-logs "$@"; }

## ----------------------------------------------------------------------------
## Parse command-line arguments.
## ----------------------------------------------------------------------------

POSITIONAL=()
IP=
IP_FILE=
USER_NAME=
OUTPUT_PATH=
DEBUG=

while [[ $# -gt 0 ]]; do
    case "$1" in
        -h|--host)
            IP="$2"
            shift; shift
            ;;

        -c|--cluster)
            IP_FILE="$2"
            shift; shift
            ;;

        -u|--user)
            USER_NAME="$2"
            shift; shift
            ;;

        -p|--path)
            LOCAL_PATH="$2"
            shift; shift
            ;;

        -d|--debug)
            DEBUG=1
            shift
            ;;

        *)
            POSITIONAL+=("$1")
            shift
            ;;
    esac
done

## Restore the positional args ready to parse normally.

set -- "${POSITIONAL[@]}"

## Ensure legal usage.

if [[ ! -z ${IP} && ! -z ${IP_FILE} ]]; then
    abort "please specify either remote host or cluster file but not both"
fi

## Parse a command.

function do-command {
    local command=$1;
    
    case $1 in
        identify)
            if [ "$IP_FILE" != "" ]; then
                identify-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                identify-host "${IP}"
            else
                identify
            fi
            ;;

        adopt)
            if [ "$IP_FILE" != "" ]; then
                adopt-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                adopt-host "${IP}"
            else
                adopt
            fi
            ;;

        authorize)
            if [ "$IP_FILE" != "" ]; then
                authorize-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                authorize-host "${IP}"
            else
                abort "please specify (-h) remote host or (-c) cluster file"
            fi
            ;;

        make-shared)
            ## Don't check for cluster file here because we need it as an argument.
            if [ "$IP" != "" ]; then
                make-shared-remote "${IP}" "${IP_FILE}" "${LOCAL_PATH}"
            else
                make-shared "${IP_FILE}" "${LOCAL_PATH}"
            fi
            ;;

        deploy-shared)
            if [ "$IP_FILE" != "" ]; then
                deploy-shared-to-cluster "${IP_FILE}" "${LOCAL_PATH}"
            elif [ "$IP" != "" ]; then
                deploy-shared-to-host "${IP}" "${LOCAL_PATH}"
            else
                deploy-shared "${LOCAL_PATH}"
            fi
            ;;

        archive-shared)
            if [ "$IP_FILE" != "" ]; then
                archive-shared-on-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                archive-shared-on-host "${IP}"
            else
                archive-shared
            fi
            ;;

        setup)
            if [ "$IP_FILE" != "" ]; then
                setup-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                setup-host "${IP}"
            else
                setup
            fi
            ;;

        clone)
            if [ "$IP_FILE" != "" ]; then
                abort "can't do this on a remote host or cluster"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host or cluster"
            else
                clone
            fi
            ;;

        build)
            if [ "$IP_FILE" != "" ]; then
                abort "can't do this on a remote host or cluster"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host or cluster"
            else
                build
            fi
            ;;

        package)
            if [ "$IP_FILE" != "" ]; then
                abort "can't do this on a remote host or cluster"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host or cluster"
            else
                package
            fi
            ;;

        deploy-app)
            if [ "$IP_FILE" != "" ]; then
                deploy-app-to-cluster "${IP_FILE}" "${LOCAL_PATH}"
            elif [ "$IP" != "" ]; then
                deploy-app-to-host "${IP}" "${LOCAL_PATH}"
            else
                deploy-app "${LOCAL_PATH}"
            fi
            ;;

        clean-data)
            if [ "$IP_FILE" != "" ]; then
                clean-cluster-data "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                clean-host-data "${IP}"
            else
                clean-data
            fi
            ;;

        scrub-data)
            if [ "$IP_FILE" != "" ]; then
                scrub-cluster-data "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                scrub-host-data "${IP}"
            else
                scrub-data
            fi
            ;;

        clean-logs)
            if [ "$IP_FILE" != "" ]; then
                clean-cluster-logs "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                clean-host-logs "${IP}"
            else
                clean-logs
            fi
            ;;

        start-slave)
            if [ "$IP_FILE" != "" ]; then
                start-cluster-slaves "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                start-remote-slave "${IP}"
            else
                start-slave
            fi
            ;;

        start-master)
            if [ "$IP_FILE" != "" ]; then
                start-cluster-masters "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                start-remote-master "${IP}"
            else
                start-master
            fi
            ;;

        start)
            if [ "$IP_FILE" != "" ]; then
                start-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host.  Please specify (-c) cluster file"
            else
                abort "please specify (-c) cluster file"
            fi
            ;;

        stop-slave)
            if [ "$IP_FILE" != "" ]; then
                stop-cluster-slaves "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                stop-remote-slave "${IP}"
            else
                stop-slave
            fi
            ;;

        stop-master)
            if [ "$IP_FILE" != "" ]; then
                stop-cluster-masters "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                stop-remote-master "${IP}"
            else
                stop-master
            fi
            ;;

        stop)
            if [ "$IP_FILE" != "" ]; then
                stop-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host.  Please specify (-c) cluster file"
            else
                abort "please specify (-c) cluster file"
            fi
            ;;

        start-simulator)
            if [ "$IP_FILE" != "" ]; then
                start-cluster-simulators "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                start-remote-simulator "${IP}"
            else
                start-simulator
            fi
            ;;

        stop-simulator)
            if [ "$IP_FILE" != "" ]; then
                stop-cluster-simulators "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                stop-remote-simulator "${IP}"
            else
                stop-simulator
            fi
            ;;

        monitor-slave)
            if [ "$IP_FILE" != "" ]; then
                monitor-cluster-slaves "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                monitor-remote-slave "${IP}"
            else
                monitor-slave
            fi
            ;;

        monitor-master)
            if [ "$IP_FILE" != "" ]; then
                monitor-cluster-masters "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                monitor-remote-master "${IP}"
            else
                monitor-master
            fi
            ;;

        monitor)
            if [ "$IP_FILE" != "" ]; then
                monitor-cluster "${IP_FILE}"
            elif [ "$IP" != "" ]; then
                abort "can't do this on a remote host.  Please specify (-c) cluster file"
            else
                abort "please specify (-c) cluster file"
            fi
            ;;

        *)
            abort "Unexpected or no task specified (expecting 'identify', 'adopt', 'authorize', 'shared', 'deploy-shared', 'setup', 'clone', 'build', 'package', 'deploy-app', 'start-slave', 'start-master', 'start', 'stop-slave', 'stop-master', 'stop')"
            ;;
    esac
}


## ----------------------------------------------------------------------------
## Entry point.
## ----------------------------------------------------------------------------

for command in $@; do
    do-command $command
done

